{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsaee/ai_chat_openAI/blob/master/007_langchain_prompt_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "프롬프트는 LLM에서 최적의 답변을 도출하기 위한 모듈이다.\n",
        "\n",
        "# 프롬프트 템플릿이란?\n",
        "- 랭체인의 답변 템플릿은 사용자 입력으로 부터 답변을 생성하기 위한 템플릿이다. 프롬프트 템플릿에는 LLM에 대한 지시, LLM에 대한 질문, LLM이 더 나은 답변을 작성하는데 도움이 되는 답변 예시와 같은 정보가 포함된다.\n",
        "- 랭체인에서 제공하는 프롬프트 템플릿 목록\n",
        "  - PromptTemplate :  프롬프트 템플릿 기본 클래스\n",
        "  - FewShotPromptTemplate : 답변 예시가 있는 프롬프트 템플릿\n",
        "  "
      ],
      "metadata": {
        "id": "C0Tw0dkI1doR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ2KGyLJ99Yi"
      },
      "source": [
        "# 랭체인 사전 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkPbwp6-ploX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4379e06-2540-44b5-c634-b7938170fb51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.354\n",
            "  Downloading langchain-0.0.354-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.3/803.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.354)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.354)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.8 (from langchain==0.0.354)\n",
            "  Downloading langchain_community-0.0.8-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.5 (from langchain==0.0.354)\n",
            "  Downloading langchain_core-0.1.6-py3-none-any.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.77 (from langchain==0.0.354)\n",
            "  Downloading langsmith-0.0.77-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.354)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.354)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.354)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.5->langchain==0.0.354) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.5->langchain==0.0.354) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.354) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.354) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.354) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.354) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.354) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.354) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.5->langchain==0.0.354) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.5->langchain==0.0.354) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.354)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.354 langchain-community-0.0.8 langchain-core-0.1.6 langsmith-0.0.77 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 패키지 설치\n",
        "!pip install langchain==0.0.354\n",
        "!pip install openai==0.28.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gf8Rfw2MiG_"
      },
      "outputs": [],
      "source": [
        "# 환경변수 준비\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NJNp0nnOjW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a56f643c-e7a6-42a8-9892-9d83284c3443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# 패키지 설치\n",
        "!pip install tiktoken\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPJ2lQW0-J3a"
      },
      "source": [
        "# 프롬프트 템플릿 생성\n",
        "```python\n",
        "PromptTemplate(\n",
        "    input_variables=[],\n",
        "    template=\"멋진 동물이라고 하면?\"\n",
        ")\n",
        "```\n",
        "- PromptTempalte() 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|input_variables|입력 변수 이름의 배열|\n",
        "|template|템플릿 문자열|"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "①  입력 변수가 없는 프롬프트 템플릿\n",
        "- 입력변수가 없는 경우 PromptTemplate 클래스의 생성자에서 input_variables에 빈 배열을 지정한다.\n",
        "- 프롬프트 템플릿을 생성한 후 format( )으로 프롬프트를 생성한다.\n",
        "- 입력변수가 없으면 설정된 템플릿의 문자열이 그대로 출력된다."
      ],
      "metadata": {
        "id": "iZjKwoRq3LSc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBYKjuiZBAXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3877d1a-ef62-49ff-a7b9-fefdc7fd3fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "멋진 동물이라고 하면?\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# 입력 변수가 없는 프롬프트 템플릿 만들기\n",
        "no_input_prompt = PromptTemplate(\n",
        "    input_variables=[],\n",
        "    template=\"멋진 동물이라고 하면?\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(no_input_prompt.format())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "② 하나의 입력 변수가 있는 프롬프트 템플릿\n",
        "- 입력변수가 없는 경우 PromptTemplate 클래스의 생성자에서 input_variables에 입력변수 이름의 배열을 지정하고, format( )에 입력변수 값을 전달하면 템플릿의 '{입력변수명}'에 입력 변수의 값이 삽입된다.\n"
      ],
      "metadata": {
        "id": "wD14Y9cN35Gu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT6TOM9YXFbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cf3f1d-8b9c-4224-9f4d-2a814cd6a2a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "멋진 동물이라고 하면?\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# 하나의 입력 변수가 있는 프롬프트 템플릿 만들기\n",
        "one_input_prompt = PromptTemplate(\n",
        "    input_variables=[\"content\"],\n",
        "    template=\"멋진 {content}이라고 하면?\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(one_input_prompt.format(content=\"동물\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "③ 여러 입력 변수가 있는 프롬프트 템플릿"
      ],
      "metadata": {
        "id": "Hm4bVr4s4c-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lsnj4yrTXfUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5dea3f-111d-43c6-ee29-7cb5c9647730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "멋진동물이라고 하면?\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# 여러 개의 입력 변수가 있는 프롬프트 템플릿 만들기\n",
        "multiple_input_prompt = PromptTemplate(\n",
        "    input_variables=[\"adjective\", \"content\"],\n",
        "    template=\"{adjective}{content}이라고 하면?\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(multiple_input_prompt.format(adjective=\"멋진\", content=\"동물\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "④ Jinja2로 프롬프트 템플릿 만들기\n",
        "- 랭체인의 프롬프트 템플릿은 템플릿 엔진의 Jinja2의 서식도 지원한다.\n",
        "- Jinja2는 파이썬의 템플릿 엔진 중 하나로, 동적인 웹 페이지를 만드는데 사용된다.\n",
        "- Jinja공식문서 https://jinja.palletsprojects.com/en/3.1.x/"
      ],
      "metadata": {
        "id": "3gajSolG4uIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk7zBZyxX6rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e261cd-b33b-4595-983a-b89e5ce332ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Q: foo\n",
            "A: bar\n",
            "\n",
            "Q: 1\n",
            "A: 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# jinja2를 이용한 프롬프트 템플릿 준비\n",
        "jinja2_prompt = PromptTemplate(\n",
        "    input_variables=[\"items\"],\n",
        "    template_format=\"jinja2\",\n",
        "    template=\"\"\"\n",
        "{% for item in items %}\n",
        "Q: {{ item.question }}\n",
        "A: {{ item.answer }}\n",
        "{% endfor %}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "items=[\n",
        "    {\"question\": \"foo\", \"answer\": \"bar\"},\n",
        "    {\"question\": \"1\", \"answer\": \"2\"}\n",
        "]\n",
        "print(jinja2_prompt.format(items=items))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0QvwzcRFj10"
      },
      "source": [
        "# 답변 예시가 포함된 프롬프트 템플릿\n",
        "- 답변 예시가 포함된 프롬프트 템플릿을 만들려면 FewShotPromptTemplate 클래스를 사용한다.\n",
        "\n",
        "- FewShotPromptTemplate(  ) 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|examples|답변예시|\n",
        "|example_prompt|프롬프트 템플릿|\n",
        "|prefix|접두사|\n",
        "|suffix|접미사|\n",
        "|input_variables|입력변수|\n",
        "|example_separator|구분기호|\n",
        "\n",
        "- 프롬프트에 답변 예시를 포함시킴으로써 LLM 답변의 정확도를 높일 수 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcjLrvZ6Fk-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ca3277-6f24-4eb2-8aa5-be14d4c219e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모든 입력에 대한 반의어를 입력하세요\n",
            "\n",
            "입력: 밝은\n",
            "출력: 어두운\n",
            "\n",
            "입력: 재미있는\n",
            "출력: 지루한\n",
            "\n",
            "입력: 큰\n",
            "출력:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "# 답변 예시 준비\n",
        "examples = [\n",
        "    {\"input\": \"밝은\", \"output\": \"어두운\"},\n",
        "    {\"input\": \"재미있는\", \"output\": \"지루한\"},\n",
        "]\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"입력: {input}\\n출력: {output}\",\n",
        ")\n",
        "\n",
        "# 답변 예시를 포함한 프롬프트 템플릿 만들기\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    examples=examples, # 답변 예시\n",
        "    example_prompt=example_prompt, # 프롬프트 템플릿\n",
        "    prefix=\"모든 입력에 대한 반의어를 입력하세요\", # 접두사\n",
        "    suffix=\"입력: {adjective}\\n출력:\", # 접미사\n",
        "    input_variables=[\"adjective\"], # 입력 변수\n",
        "    example_separator=\"\\n\\n\" # 구분 기호\n",
        "\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(prompt_from_string_examples.format(adjective=\"큰\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다양한 답변 예시가 포함된 프롬프트 템플릿\n",
        "- 여러개의 답변 예시가 포함된 프롬프트 템플릿을 만들려면 ExampleSelector 클래스를 상속받아 사용한다.\n",
        "- 답변 예시가 여러 개인 경우 어떤 예시를 사용할지 선택하는 선택기가 된다.\n",
        "   - LengthBasedExampleSelector\n",
        "   - SemanticSimilarityExampleSelector\n",
        "   - MaxMarginalRelevanceExampleSelector"
      ],
      "metadata": {
        "id": "PRJg4v6x7TLN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDyN588AFvt9"
      },
      "source": [
        "# LengthBasedExampleSelector\n",
        "- LengthBasedExampleSelector는 문자열 길이를 기준으로 사용할 답변 예시를 선택한다.\n",
        "- 이것은 입력된 토큰 수가 최대 토큰 수를 초과할 우려가 있을 때 유용하다.\n",
        "- 입력이 길면 답변예시를 적게 포함하고, 입력이 짧으면 답변 예시를 많이 포함한다.\n",
        "- LengthBasedExampleSelector( ) 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|examples|답변예시|\n",
        "|example_prompt|프롬프트 템플릿|\n",
        "|max_length|문자열의 최대 길이|\n",
        "\n",
        "\n",
        "- 사용할 답변 선택기는 FewShotPrompTemplate 클래스의 example_selector에 지정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6N9nSJPFxO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40113cc3-be8c-46e3-a9b2-4cbdeb4dd24d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모든 입력에 대한 반의어를 입력하세요\n",
            "\n",
            "입력: 밝은\n",
            "출력: 어두운\n",
            "\n",
            "입력: 재미있는\n",
            "출력: 지루한\n",
            "\n",
            "입력: 큰\n",
            "출력:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import FewShotPromptTemplate\n",
        "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
        "\n",
        "# 답변 예시 준비\n",
        "examples = [\n",
        "    {\"input\": \"밝은\", \"output\": \"어두운\"},\n",
        "    {\"input\": \"재미있는\", \"output\": \"지루한\"},\n",
        "    {\"input\": \"활기찬\", \"output\": \"무기력한\"},\n",
        "    {\"input\": \"높은\", \"output\": \"낮은\"},\n",
        "    {\"input\": \"빠른\", \"output\": \"느린\"},\n",
        "]\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"입력: {input}\\n출력: {output}\",\n",
        ")\n",
        "\n",
        "# LengthBasedExampleSelector 생성\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples=examples, # 답변 예시\n",
        "    example_prompt=example_prompt, # 프롬프트 템플릿\n",
        "    max_length=10, # 문자열의 최대 길이\n",
        ")\n",
        "\n",
        "# FewShotPromptTemplate 생성\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,  # ExampleSelector\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"모든 입력에 대한 반의어를 입력하세요\",\n",
        "    suffix=\"입력: {adjective}\\n출력:\",\n",
        "    input_variables=[\"adjective\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(prompt_from_string_examples.format(adjective=\"큰\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRdaDPJ9G9PX"
      },
      "source": [
        "# SemanticSimilarityExampleSelector\n",
        "- SemanticSimilarityExampleSelector는 입력과 가장 유사한 답변 예제를 기준으로 답변 예제를 선택한다.\n",
        "- 입력과 코사인 유사도(consine similarity)가 가장 높은 임베딩을 사용해 답변 예시를 찾는다.\n",
        "- SemanticSimilarityExampleSelector.from_examples( ) 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|examples|답변예시|\n",
        "|embeddings|임베디드 생성 클래스|\n",
        "|vectorstore_cls|임베디드 유사 검색 클래스|\n",
        "|k|답변 예시 개수|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlXjHv5FHB4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbd9633-3ab7-4ad5-d060-2b7d9e3d7034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모든 입력에 대한 반의어를 입력하세요\n",
            "\n",
            "입력: 밝은\n",
            "출력: 어두운\n",
            "\n",
            "입력: 재미있는\n",
            "출력: 지루한\n",
            "\n",
            "입력: 높은\n",
            "출력: 낮은\n",
            "\n",
            "입력: \n",
            "출력:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "# 답변 예시 준비\n",
        "examples = [\n",
        "    {\"input\": \"밝은\", \"output\": \"어두운\"},\n",
        "    {\"input\": \"재미있는\", \"output\": \"지루한\"},\n",
        "    {\"input\": \"활기찬\", \"output\": \"무기력한\"},\n",
        "    {\"input\": \"높은\", \"output\": \"낮은\"},\n",
        "    {\"input\": \"빠른\", \"output\": \"느린\"},\n",
        "]\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"입력: {input}\\n출력: {output}\",\n",
        ")\n",
        "\n",
        "# SemanticSimilarityExampleSelector 생성\n",
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    examples=examples, # 답변 예시\n",
        "    embeddings=OpenAIEmbeddings(), # 임베디드 생성 클래스\n",
        "    vectorstore_cls=FAISS, # 임베디드 유사 검색 클래스\n",
        "    k=3 # 답변 예시 개수\n",
        ")\n",
        "\n",
        "# FewShotPromptTemplate 생성\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,  # ExampleSelector\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"모든 입력에 대한 반의어를 입력하세요\",\n",
        "    suffix=\"입력: {adjective}\\n출력:\",\n",
        "    input_variables=[\"adjective\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(prompt_from_string_examples.format(adjective=\"큰\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZBrH6W-HFLs"
      },
      "source": [
        "# MaxMarginalRelevanceExampleSelector\n",
        "- MaxMarginalRelevanceExampleSelector는 다양성을 최적화하면서 입력과 가장 유사한 답변 예시 조합을 기반으로 답변 예시를 선택한다.\n",
        "- 입력과 코사인 유사도가 가장 높은 답변 예시를 찾으면서 이미 선택된 답변 예시와 유사한 답변 예시는 포함하지 않도록 한다.\n",
        "\n",
        "- MaxMarginalRelevanceExampleSelector.from_examples( )주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|examples|답변 예시|\n",
        "|embeddings|임베디드 생성 클래스|\n",
        "|vectorstore_cls|임베디드 유사 검색 클래스|\n",
        "|k|답변 예시 개수|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTYHBw6LHFgR"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.example_selector import MaxMarginalRelevanceExampleSelector\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "# 답변 예시 준비\n",
        "examples = [\n",
        "    {\"input\": \"밝은\", \"output\": \"어두운\"},\n",
        "    {\"input\": \"재미있는\", \"output\": \"지루한\"},\n",
        "    {\"input\": \"활기찬\", \"output\": \"무기력한\"},\n",
        "    {\"input\": \"높은\", \"output\": \"낮은\"},\n",
        "    {\"input\": \"빠른\", \"output\": \"느린\"},\n",
        "]\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"입력: {input}\\n출력: {output}\",\n",
        ")\n",
        "\n",
        "# MaxMarginalRelevanceExampleSelector 생성\n",
        "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
        "    examples=examples, # 답변 예시\n",
        "    embeddings=OpenAIEmbeddings(), # 임베디드 생성 클래스\n",
        "    vectorstore_cls=FAISS, # 임베디드 유사 검색 클래스\n",
        "    k=3 # 답변 예시 개수\n",
        ")\n",
        "\n",
        "# FewShotPromptTemplate 준비\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"모든 입력에 대한 반의어를 입력하세요\",\n",
        "    suffix=\"입력: {adjective}\\n출력:\",\n",
        "    input_variables=[\"adjective\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(prompt_from_string_examples.format(adjective=\"큰\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}