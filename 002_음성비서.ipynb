{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPESm0UEe5kIS2b3OQjNbH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsaee/ai_chat_openAI/blob/master/002_%EC%9D%8C%EC%84%B1%EB%B9%84%EC%84%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uMp2wprOVls",
        "outputId": "b06e1691-723a-4291-b841-96b26740183b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ai_chat_openAI\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/MyDrive/ai_chat_openAI'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 수신자 모두\n",
        "### 1. 텍스트를 음성 파일로 변환하는 gTTS 사용\n",
        "\n",
        "- 텍스트를 음성파일로 변환하는 TTS(Text-To-Speech)\n",
        "- TTS 기능을 구현하기 위해 gTTS라는 무료 TTS 패키지를 사용\n",
        "  - gTTS 공식 홈페이지 https://pypi.org/project/gTTS/\n",
        "  - 구글 클라우드의 유료 TTS 서비스 https://cloud.google.com/text-to-speech?hl=ko\n"
      ],
      "metadata": {
        "id": "ekDRBaUaOirb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.org/project/gTTS/\n",
        "!pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ2CnlsgOmmT",
        "outputId": "de0c9dd7-8072-42ec-d644-fb8fe4d96be2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.11.17)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "tts = gTTS(text='안녕하세요 음성비서 프로그램 실습중입니다.', lang='ko')\n",
        "tts.save('output.mp3')"
      ],
      "metadata": {
        "id": "o6Panf23Op7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 음성 파일을  텍스트로 변환하는 Whisper API 사용\n",
        "\n",
        "- Whisper란  ChatGPT로 유명한 OpenAI에서 공개한 인공지능 모델로, 음성을 텍스트로 변환해 주는 Speech to Text(STT) 기술이다.\n",
        "- 약 68만 시간 분량의 방대한 데이터를 학습시켜 영어, 한국어를 포함한 다양한 언어를 인식할 수 있으며, 번역 및 언어 식별 기능이 있다.\n",
        "- Whisper 모델은 오픈소스로 공개돼 있으며 구체적인 모델의 구조는 공식 홈페이지에서 확인할 수 있다.\n",
        " -  https://openai.com/research/whisper\n",
        "- Whisper 가격\n",
        " - https://openai.com/pricing"
      ],
      "metadata": {
        "id": "RZJ2-qjnPt4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQvQemXlQkPu",
        "outputId": "09aebaa2-4c52-4d9a-d3c2-6614e51d03ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# API 키 입력하기.\n",
        "# openai.api_key = 'API Key'\n",
        "openai.api_key = \"sk-\"\n",
        "\n",
        "# 녹음파일 열기\n",
        "audio_file = open(\"output.mp3\",\"rb\")\n",
        "# whisper 모델에 음원파일 전달하기.\n",
        "transcript = openai.Audio.transcribe('whisper-1',audio_file)\n",
        "print(dir(transcript))\n",
        "\n",
        "# 결과보기\n",
        "print(transcript['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI36JQ7IP7Ge",
        "outputId": "777f79d2-3c32-435d-f38f-c8bfb8a1132a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__class_getitem__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_previous', '_response_ms', '_retrieve_params', 'api_base', 'api_base_override', 'api_key', 'api_type', 'api_version', 'arequest', 'clear', 'construct_from', 'copy', 'engine', 'fromkeys', 'get', 'items', 'keys', 'openai_id', 'organization', 'pop', 'popitem', 'refresh_from', 'request', 'response_ms', 'setdefault', 'to_dict', 'to_dict_recursive', 'typed_api_type', 'update', 'values']\n",
            "안녕하세요 음성비서 프로그램 실습 중입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 프로그램 UI를 생성하는 스트림릿 사용\n",
        "\n",
        "- 스트림릿(Streamlit)은 데이터 과학, 머신러닝, 분석 프로젝트를 위한 웹 어플리케이션을 만드는 과정을 간소화하고, 신속하게 웹 애플리케이션을 만들 수 있게 설계된 오픈소스이다.\n",
        "- 사용자가 앱을 사용할 때 실제로 보는 타이틀, 버튼과 같은 UI를 손쉽게 만들 수 있으며, 직관적이고 사용자 친화적인 프레임워크이다.\n",
        "- 스트림릿을 활용하면 웹 개발에 대한 광범위한 지식이 없더라도 간단한 파이썬 스크립트 작성으로 애플리케이션을 빠르게 구축할 수 있다.\n",
        "- 스트림릿 주요 기능과 장점\n",
        "  - 간단한 사용법 : 스트림릿의 문법은 매우 간단하여 파이썬을 기초 수준으로 이해하는 사용자라면 손쉽게 사용할 수 있다.\n",
        "  - 빠른 개발 속도 : 웹 애플리케이션을 빠르게 빌드할 수 있으며, 반복적인 프로토타이핑과 배포 속도를 높일 수 있다.\n",
        "  - 뛰어난 인터렉티브 기능 : 스트림릿에 내장된 위젯을 사용하면 최소한의 코딩으로 사용자와 원활한 상호 작용이 가능하다.\n",
        "  - 시각적 사용자 정의 기능 : 스트림릿은 Matplotlib, Plotly, Altair와 같이 널리 사용되는 데이터 시각화 라이브러리를 쉽게 통합할 수 있어 다양한 시각적 사용자 정의가 가능하다.\n",
        "  - 실시간 업데이트 : 코드를 수정하면 스트림릿 애플리케이션이 자동 업데이트되어 효율적인 개발 환경을 제공한다.\n",
        "  - 간편한 공유 기능 : 간소화된 배포 프로세스를 제공하여 다른 사용자에게 애플리케이션을 쉽게 공유할 수 있다.\n",
        "\n",
        "|기능|Streamlit|Django|Flask|\n",
        "|---|---|---|---|\n",
        "|데이터 과학 및 머신 러닝에 특화| ㅇ | X | X |\n",
        "|사용의 용이성|높음(최소한의 코딩 필요) | 중간(많은 학습 필요)|중간(웹 개발 이해 필요)|\n",
        "|웹 개발 지식 필요여부| X | ㅇ | ㅇ |\n",
        "\n",
        "\n",
        "- 스트림릿 기본 함수\n",
        "  - st.title( ) : 앱에 제목을 생성한다.\n",
        "  - st.header( ) : 앱에 헤더를 생성한다.\n",
        "  - st.subheader( ) : 앱에 서브헤더를 생성한다.\n",
        "  - st.text( ) : 앱에 일반 텍스트를 생성한다.\n",
        "  - st.write( ) : 앱에 텍스트나 데이터를 생성한다. 이 함수를 다용도로 사용할 수 있으며 텍스트, 데이터 프레임 또는 플롯을 표시할 수 있다."
      ],
      "metadata": {
        "id": "halhbG4wUIt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IM4fQ5NU16R",
        "outputId": "c1213c3e-b33d-4f27-821e-2ac8e5ad8bb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.29.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Collecting importlib-metadata<7,>=1.4 (from streamlit)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, importlib-metadata, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.40 importlib-metadata-6.11.0 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.29.0 validators-0.22.0 watchdog-3.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.4-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_example.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"나의 첫 번째 Streamlit 앱\")\n",
        "\n",
        "st.header(\"Streamlit에 오신 것을 환영합니다.\")\n",
        "st.subheader(\"웹 앱을 만들기 위한 강력하고 사용하기 쉬운 라이브러리\")\n",
        "\n",
        "st.text(\"이것은 일반 텍스트입니다.\")\n",
        "\n",
        "st.write(\"write()함수를 사용하여 텍스트, 데이터 또는 플롯을 표시할 수도 있습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYmynWM8Ve6i",
        "outputId": "199dd319-1ee5-48de-b2f6-ccca0cda5565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_example.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "#!streamlit run /content/drive/MyDrive/open_ai_chat/streamlit_example.py --server.port=5000\n",
        "!streamlit run streamlit_example.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXCUj2soWl4R",
        "outputId": "a3c7e62f-9062-42b7-ca76-37c35ced857c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://676a-35-201-131-121.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.201.131.121:5000\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-12-27T08:31:59+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-37ae3d71-ea48-4c94-88b2-24157eb8bf29 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 스트림릿으로 음성 비서 프로그램의 UI 만들기\n",
        "\n",
        "- 기본 설명 영역 : 제목과 기본 정보를 설명하는 영역이다.\n",
        "- 옵션 선택 영역 : OpenAI API 키를 입력받고, GPT 모델을 선택하기 위한 라디오 버튼과 초기화 버튼이 있는 영역이다.\n",
        "- 기능 구현 영역 : 음성을 녹음하고, 녹음한 음성을 재생하는 기능과 이를 채팅창 화면으로 보여주는 영역이다."
      ],
      "metadata": {
        "id": "HvXMdIXbZ8Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "def main():\n",
        "  st.set_page_config(\n",
        "      page_title = '음성 비서 프로그램',\n",
        "      layout='wide')\n",
        "\n",
        "  st.header('음성 비서 프로그램')\n",
        "  st.markdown('----------------')\n",
        "\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        ''')\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lnAxbWtaYR7",
        "outputId": "13590003-fa6d-4360-bb8c-dbb144d02c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBloex8Zb7lP",
        "outputId": "68c9a91c-7fac-4333-da7e-4728756a55b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://4819-35-201-131-121.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.201.131.121:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "\n",
        "def main():\n",
        "  st.set_page_config(\n",
        "      page_title = '음성 비서 프로그램',\n",
        "      layout='wide')\n",
        "\n",
        "  st.header('음성 비서 프로그램')\n",
        "  st.markdown('----------------')\n",
        "\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        ''')\n",
        "  # 사이드바 생성\n",
        "  with st.sidebar:\n",
        "    openai.api_key = st.text_input(label='OPENAPI API 키', placeholder='Enter Your API Key', value='sk-', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4','gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      pass\n",
        "\n",
        "  # 기능 구현 공간\n",
        "  col1, col2= st.columns(2) # 두개의 영역으로 분할하기.\n",
        "  with col1:\n",
        "    # 왼쪽 영역 작성\n",
        "    st.subheader('질문하기')\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 작성\n",
        "    st.subheader('질문/답변')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aAaVcRFcexI",
        "outputId": "ec19e9ec-847f-457e-ae13-bc66b589f011"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2rGHuOId_L_",
        "outputId": "32924aef-351b-49a0-e5da-72052fa9502b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://40a2-34-106-180-103.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.180.103:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 스트림릿의 상태를 저장하기 위한 session_state 함수\n",
        "\n",
        "- 스트림릿 프로그램은 사용자가 버튼을 누르거나 텍스트를 입력할 때마다 코드가 처음부터 끝까지 재실행되는데, 이 과정에서 내부의 모든 변수가 초기화 된다.\n",
        "- 예를 들어, ChatGPT에게 처음 질문을 한 후 이어서 두 번째 질문을 하기 위해 녹음 버튼을 한 번 더 클릭하면 프로그램이 처음부터 다시 실행된다.\n",
        "- 이로 인해 변수들이 모두 초기화되고, 첫번째 질문의 기록이 사라지는 문제가 발생한다. 이러한 문제를 해결하는 방법이 session_state이다.\n",
        "- st.session_state는 스트림릿에서 사용하는 저장 공간으로, session_state을 이용하면 프로그램을 재실행하더라도 정보가 초기화되지 않고 계속 유지된다.\n",
        "- session_state는 파이썬의 딕셔너리 형태로 여러 개의 정보를 저장할 수 있다.\n",
        "---\n",
        "상태를 저장하기 위한 session_state 추가  \n",
        "\n",
        "- st.session_state['chat'] : 사용자와 음성 비서의 대화 내용을 저장하여 채팅창에 표시하는데 사용한다.\n",
        "- st.session_state['message'] : GPT API에 입력(input)으로 전달할 프롬프트 양식을 저장한다. 이전 질문과 답변 모두 차례로 누적하여 저장한다.\n",
        "- st.session_state['check_audio'] : 프로그램이 다시 실행될 때 마다 이전 녹음 파일의 정보가 버퍼에 남아서 실행되는 것을 방지하기 위해 사용자가 녹음한 음원을 리스트 형태로 저장한다. 새로운 녹음이 들어오면 저장해 둔 음원과 비교하여 새로운 녹음인지 판단한다."
      ],
      "metadata": {
        "id": "7mgkl05B_ehP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "\n",
        "def main():\n",
        "  st.set_page_config(\n",
        "      page_title = '음성 비서 프로그램',\n",
        "      layout='wide')\n",
        "\n",
        "  # session_state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"]=[{\"role\":\"system\",\n",
        "                                   \"content\":\"You are a thoughtful assistant. Respond to all input in 25 words and answer in korean\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"]=False\n",
        "\n",
        "  # 제목 생성\n",
        "  st.header('음성 비서 프로그램')\n",
        "  st.markdown('----------------')\n",
        "\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        ''')\n",
        "  # 사이드바 생성\n",
        "  with st.sidebar:\n",
        "    openai.api_key = st.text_input(label='OPENAPI API 키', placeholder='Enter Your API Key', value='sk-', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4','gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      st.session_state['chat']=[]\n",
        "      st.session_state['message']=[{'role':'system',\n",
        "                                    'content':'You are a thoughtful assistant. Respond to all input in 25 words and answer in korean'}]\n",
        "      st.session_state[\"check_reset\"]=True\n",
        "\n",
        "  # 기능 구현 공간\n",
        "  col1, col2= st.columns(2) # 두개의 영역으로 분할하기.\n",
        "  with col1:\n",
        "    # 왼쪽 영역 작성\n",
        "    st.subheader('질문하기')\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 작성\n",
        "    st.subheader('질문/답변')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOQh8Vm8ARIW",
        "outputId": "2f5ddecb-be75-4d5b-a93b-4af7613bb694"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q77nETTCBSHn",
        "outputId": "83d9df81-6161-4cd7-bd00-a0a2b85be23f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://87ed-34-106-180-103.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.180.103:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 스트림릿 오디오 레코더를 활용하여 음성 녹음하기\n",
        "- 스트림릿의 기본 패키지에는 음성을 녹음하기 위한 기능이 없으므로 streamlit-audiorecorder라는  새로운 패키지를 설치한다.\n",
        "- streamlit-audiorecorder를 활용하면 스트림릿에서 음성 녹음 버튼을 생성하고, 녹음 결과를 파일로 저장할 수 있다."
      ],
      "metadata": {
        "id": "DaR-RgyDGgxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit-audiorecorder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D63rkDORHqiE",
        "outputId": "4f95f3ba-f1e7-46bb-c9c9-f5182a3401d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit-audiorecorder\n",
            "  Downloading streamlit_audiorecorder-0.0.4-py3-none-any.whl (447 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit-audiorecorder) (1.29.0)\n",
            "Collecting pydub>=0.24 (from streamlit-audiorecorder)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (6.11.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-audiorecorder) (4.0.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit-audiorecorder) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-audiorecorder) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit-audiorecorder) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-audiorecorder) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (0.1.2)\n",
            "Installing collected packages: pydub, streamlit-audiorecorder\n",
            "Successfully installed pydub-0.25.1 streamlit-audiorecorder-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audiorecorder import audiorecorder\n",
        "print(dir(audiorecorder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u90PopTaHvr2",
        "outputId": "bb663591-6111-4083-80c1-706e6cb8d3fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "\n",
        "# 패키지 추가(오디오 레코더, 파일삭제, 시간정보)\n",
        "from audiorecorder import audiorecorder\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def main():\n",
        "  st.set_page_config(\n",
        "      page_title = '음성 비서 프로그램',\n",
        "      layout='wide')\n",
        "\n",
        "  # session_state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"]=[{\"role\":\"system\",\n",
        "                                   \"content\":\"You are a thoughtful assistant. Respond to all input in 25 words and answer in korean\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"]=False\n",
        "\n",
        "  # 제목 생성\n",
        "  st.header('음성 비서 프로그램')\n",
        "  st.markdown('---')\n",
        "\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        ''')\n",
        "  # 사이드바 생성\n",
        "  with st.sidebar:\n",
        "    openai.api_key = st.text_input(label='OPENAPI API 키', placeholder='Enter Your API Key', value='sk-', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4','gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      st.session_state['chat']=[]\n",
        "      st.session_state['message']=[{'role':'system',\n",
        "                                    'content':'You are a thoughtful assistant. Respond to all input in 25 words and answer in korean'}]\n",
        "      st.session_state[\"check_reset\"]=True\n",
        "\n",
        "  # 기능 구현 공간\n",
        "  col1, col2= st.columns(2) # 두개의 영역으로 분할하기.\n",
        "  with col1:\n",
        "    # 왼쪽 영역 작성\n",
        "    st.subheader('질문하기')\n",
        "    audio = audiorecorder(\"클릭하여 녹음하기\", \"녹음중...\") #(start, stop, pause)\n",
        "\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      st.audio(audio.export().read())\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 작성\n",
        "    st.subheader('질문/답변')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6hjKXArIw5s",
        "outputId": "94d2a790-9802-4c52-d465-3b223521897b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZPnODnEJGjs",
        "outputId": "d4bf9f13-1e00-40d3-b0b2-5299c19dc945"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://cb6f-34-106-180-103.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.180.103:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 음성파일 텍스트파일로 변환하기."
      ],
      "metadata": {
        "id": "oXvJ-L-RVz2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "\n",
        "# 패키지 추가(오디오 레코더, 파일삭제, 시간정보)\n",
        "from audiorecorder import audiorecorder\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# 기능 구현 함수\n",
        "def STT(audio):\n",
        "  filename = 'input.mp3'\n",
        "  audio.export(filename, format='mp3')\n",
        "\n",
        "  audio_file = open(filename, 'rb')\n",
        "\n",
        "  # whisper 모델을 활용해 텍스트 얻기\n",
        "  transcript = openai.Audio.transcribe('whisper-1', audio_file)\n",
        "  audio_file.close()\n",
        "\n",
        "  os.remove(filename)\n",
        "  return transcript['text']\n",
        "\n",
        "\n",
        "def main():\n",
        "  st.set_page_config(\n",
        "      page_title = '음성 비서 프로그램',\n",
        "      layout='wide')\n",
        "\n",
        "  # session_state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"]=[{\"role\":\"system\",\n",
        "                                   \"content\":\"You are a thoughtful assistant. Respond to all input in 25 words and answer in korean\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"]=False\n",
        "\n",
        "  # 제목 생성\n",
        "  st.header('음성 비서 프로그램')\n",
        "  st.markdown('---')\n",
        "\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        ''')\n",
        "  # 사이드바 생성\n",
        "  with st.sidebar:\n",
        "    openai.api_key = st.text_input(label='OPENAPI API 키', placeholder='Enter Your API Key', value='sk-', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4','gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      st.session_state['chat']=[]\n",
        "      st.session_state['message']=[{'role':'system',\n",
        "                                    'content':'You are a thoughtful assistant. Respond to all input in 25 words and answer in korean'}]\n",
        "      st.session_state[\"check_reset\"]=True\n",
        "\n",
        "  # 기능 구현 공간\n",
        "  col1, col2= st.columns(2) # 두개의 영역으로 분할하기.\n",
        "  with col1:\n",
        "    # 왼쪽 영역 작성\n",
        "    st.subheader('질문하기')\n",
        "    audio = audiorecorder(\"클릭하여 녹음하기\", \"녹음중...\") #(start, stop, pause)\n",
        "\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      st.audio(audio.export().read())\n",
        "\n",
        "      # 음원 파일에서 텍스트 추출\n",
        "      question = STT(audio)\n",
        "      # 텍스트 시각화 질문 내용 저장\n",
        "      now = datetime.now().strftime('%H:%M')\n",
        "      st.session_state['chat'] = st.session_state['chat'] + [('user', now, question)] # 질문 누적하기.\n",
        "\n",
        "      # GPT 프롬프트 질문 내용 저장\n",
        "      st.session_state['messages'] = st.session_state['messages'] + [{'role':'user', 'content': question}] # 응답 누적하기.\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 작성\n",
        "    st.subheader('질문/답변')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPeW2bfTVxDo",
        "outputId": "db2ab161-0f18-43ee-d3c8-db0879e149f9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "id": "_5t2fvx8YsHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. ChatGPT API로 질문하고 답변 구하기.\n",
        " - ChatGPT API를 활용하여 답변 구하기.\n",
        " - 대화 내용을 채팅 형식으로 시각화하기.\n",
        "\n",
        "\n",
        "TTS 패키지추가\n",
        "from gtts import gTTS  \n",
        "음원파일 재생 패키지추가\n",
        "import base64"
      ],
      "metadata": {
        "id": "ToGUP19GaFS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "\n",
        "# 패키지 추가(오디오 레코더, 파일삭제, 시간정보)\n",
        "from audiorecorder import audiorecorder\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# TTS, 음원재생 패키지 추가\n",
        "from gtts import gTTS\n",
        "import base64\n",
        "\n",
        "# 기능 구현 함수\n",
        "def STT(audio):\n",
        "  filename = 'input.mp3'\n",
        "  audio.export(filename, format='mp3')\n",
        "\n",
        "  audio_file = open(filename, 'rb')\n",
        "\n",
        "  # whisper 모델을 활용해 텍스트 얻기\n",
        "  transcript = openai.Audio.transcribe('whisper-1', audio_file)\n",
        "  audio_file.close()\n",
        "\n",
        "  os.remove(filename)\n",
        "  return transcript['text']\n",
        "\n",
        "def ask_gpt(prompt, model):\n",
        "  response = openai.ChatCompletion.create(model=model, messages=prompt)\n",
        "  system_message = response['choices'][0]['message']\n",
        "  return system_message['content']\n",
        "\n",
        "def TTS(response):\n",
        "  filename = 'output.mp3'\n",
        "  tts = gTTS(text=response, lang='ko')\n",
        "  tts.save(filename)\n",
        "\n",
        "  # 음원 파일 자동 생성\n",
        "  with open(filename, 'rb') as f:\n",
        "    data = f.read()\n",
        "    b64 = base64.b64encode(data).decode()\n",
        "    md = f\"\"\"\n",
        "        <audio autoplay=\"True\">\n",
        "        <source src=\"data:audio/mp3;base64,{b64}\" type=\"audio/mp3\">\n",
        "        </audio>\n",
        "        \"\"\"\n",
        "\n",
        "    st.markdown(md, unsafe_allow_html=True,)\n",
        "\n",
        "# 메인 함수\n",
        "def main():\n",
        "  st.set_page_config(\n",
        "      page_title = '음성 비서 프로그램',\n",
        "      layout='wide')\n",
        "\n",
        "  # session_state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"]=[{\"role\":\"system\",\n",
        "                                   \"content\":\"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"]=False\n",
        "\n",
        "  # 제목 생성\n",
        "  st.header('음성 비서 프로그램')\n",
        "  st.markdown('---')\n",
        "\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        ''')\n",
        "  # 사이드바 생성\n",
        "  with st.sidebar:\n",
        "    openai.api_key = st.text_input(label='OPENAPI API 키', placeholder='Enter Your API Key', value='sk-', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4','gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      st.session_state['chat']=[]\n",
        "      st.session_state['message']=[{'role':'system',\n",
        "                                    'content':'You are a thoughtful assistant. Respond to all input in 25 words and answer in korea'}]\n",
        "      st.session_state[\"check_reset\"]=True\n",
        "\n",
        "  # 기능 구현 공간\n",
        "  col1, col2= st.columns(2) # 두개의 영역으로 분할하기.\n",
        "  with col1:\n",
        "    # 왼쪽 영역 작성\n",
        "    st.subheader('질문하기')\n",
        "    audio = audiorecorder(\"클릭하여 녹음하기\", \"녹음중...\") #(start, stop, pause)\n",
        "\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      st.audio(audio.export().read())\n",
        "\n",
        "      # 음원 파일에서 텍스트 추출\n",
        "      question = STT(audio)\n",
        "      # 텍스트 시각화 질문 내용 저장\n",
        "      now = datetime.now().strftime('%H:%M')\n",
        "      st.session_state['chat'] = st.session_state['chat'] + [('user', now, question)] # 질문 누적하기.\n",
        "\n",
        "      # GPT 프롬프트 질문 내용 저장\n",
        "      st.session_state['messages'] = st.session_state['messages'] + [{'role':'user', 'content': question}] # 응답 누적하기.\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 작성\n",
        "    st.subheader('질문/답변')\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      response = ask_gpt(st.session_state['messages'], model)\n",
        "\n",
        "      # 프롬프트 답변 내용 저장\n",
        "      st.session_state['messages'] = st.session_state['messages']+[{'role':'system', 'content': response}]\n",
        "\n",
        "      # 텍스트 시각화 답변 내용 저장\n",
        "      now = datetime.now().strftime('%H:%M')\n",
        "      st.session_state['chat'] = st.session_state['chat']+[('bot',now,response)]\n",
        "\n",
        "      # 채팅 형식으로 시각화 하기\n",
        "      for sender, time, message in st.session_state['chat']:\n",
        "        if sender == 'user':\n",
        "          st.write(f'<div style=\"display:flex;align-items:center;\"><div style=\"background-color:#007AFF;color:white;border-radius:12px;padding:8px 12px;margin-right:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "          st.write(\"\")\n",
        "        else:\n",
        "          st.write(f'<div style=\"display:flex;align-items:center;justify-content:flex-end;\"><div style=\"background-color:lightgray;border-radius:12px;padding:8px 12px;margin-left:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "          st.write(\"\")\n",
        "      # gTTS를 활용하여 음성 파일 생성 및 재생\n",
        "      TTS(response)\n",
        "    else:\n",
        "      st.session_state[\"check_reset\"]=False\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk3CymsNaPyh",
        "outputId": "84e2ae07-5a45-4efd-cb12-0b2159958f7d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2pEiRdpaS8_",
        "outputId": "42f0b5c6-6244-408f-da26-f36a36eba805"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://6c3a-34-106-218-202.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.218.202:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}