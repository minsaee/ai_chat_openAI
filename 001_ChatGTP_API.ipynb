{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyIsm2RxxUpTTZjXKiEitp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsaee/ai_chat_openAI/blob/master/001_ChatGTP_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openai"
      ],
      "metadata": {
        "id": "gHFj6xoJyvSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OEFOEo213A0",
        "outputId": "34035fb7-e30c-4f0c-aa63-54010455a601"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "```python\n",
        "import openai\n",
        "\n",
        "openai.api_key='OpenAPI API Key'\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"프롬프트 입력\"}],\n",
        "  temperature=1,\n",
        "  top_p=1,\n",
        "  presence_penalty=1,\n",
        "  frequency_penalty=1,\n",
        "  n=1,\n",
        "  max_tokens=4000,\n",
        "  stop=None\n",
        ")\n",
        "\n",
        "print(response)\n",
        "```"
      ],
      "metadata": {
        "id": "DcWAsACsytxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key='sk-'\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"Tell me how to make a pizza\"}]\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfMypZ-_zQGD",
        "outputId": "dc89b947-3d3d-4099-d136-9f353825d764"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8aHBeRhf3X6Lu3aVjnzL6mYksscel\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1703656566,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Making a pizza involves several steps, including making the dough, preparing the sauce, adding toppings, and baking it. Here's a simple recipe for making a classic homemade pizza:\\n\\nIngredients:\\n- Pizza dough:\\n  - 2 \\u00bd to 3 cups all-purpose flour\\n  - 1 cup warm water\\n  - 1 packet (2 \\u00bc teaspoons) active dry yeast\\n  - 1 teaspoon sugar\\n  - 2 tablespoons olive oil\\n  - 1 teaspoon salt\\n\\n- Pizza sauce:\\n  - 1 can (14 ounces) crushed tomatoes\\n  - 1 clove garlic, minced\\n  - 1 teaspoon olive oil\\n  - 1 teaspoon dried basil\\n  - 1 teaspoon dried oregano\\n  - Salt and pepper to taste\\n\\n- Toppings:\\n  - Shredded mozzarella cheese\\n  - Any desired toppings (e.g., sliced pepperoni, bell peppers, onions, mushrooms, etc.)\\n\\nInstructions:\\n1. Make the dough:\\n- In a small bowl, combine warm water, sugar, and yeast.\\n- Let it sit for 5-10 minutes until the yeast becomes foamy.\\n- In a large mixing bowl, combine 2 \\u00bd cups of flour and salt.\\n- Create a well in the center of the flour mixture and pour in the yeast mixture and olive oil.\\n- Stir the ingredients together until they form a dough.\\n- Gradually add in more flour if needed until the dough becomes smooth and slightly sticky.\\n- Transfer the dough to a lightly floured surface and knead it for 5-7 minutes until it becomes elastic.\\n- Place the dough in a greased bowl, cover it with a clean towel, and let it rise in a warm place for about 1-2 hours until it doubles in size.\\n\\n2. Prepare the pizza sauce:\\n- In a saucepan, heat olive oil over medium heat and add minced garlic.\\n- Cook for about 1 minute until garlic becomes fragrant, but be careful not to burn it.\\n- Add crushed tomatoes, basil, oregano, salt, and pepper to taste.\\n- Reduce the heat and let the sauce simmer for about 15-20 minutes.\\n- Remove from heat and set it aside to cool.\\n\\n3. Assemble the pizza:\\n- Preheat your oven to the highest temperature possible (usually around 500\\u00b0F/260\\u00b0C).\\n- Punch down the risen dough and divide it into desired portions.\\n- On a lightly floured surface, roll out each portion into your desired pizza shape and thickness.\\n- Place the dough onto a baking sheet or a pizza stone.\\n- Spread an even layer of pizza sauce onto the dough, leaving about a \\u00bd inch border around the edges.\\n- Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\\n- Add your desired toppings, such as pepperoni, bell peppers, onions, mushrooms, etc.\\n\\n4. Bake the pizza:\\n- Place the pizza in the preheated oven and bake for about 10-15 minutes or until the crust is golden brown and the cheese is melted and bubbly.\\n- Keep an eye on it to prevent burning.\\n- Once baked, remove the pizza from the oven and let it cool for a few minutes.\\n- Slice it into pieces and serve it hot.\\n\\nEnjoy your homemade pizza!\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 14,\n",
            "    \"completion_tokens\": 674,\n",
            "    \"total_tokens\": 688\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[각 정보의 의미]\n",
        "- choices : 완료 개체 목록이다. 질문시 응답 개수(n)를 1로 설정하면 한개, 2로 설정하면 2개의 완료 개체가 리스트 형태로 저장된다.\n",
        "- index : 완료 개체의 인덱스이다.\n",
        "- message : 모델에서 생성된 메시지 내용이다. 'content'는 답변 내용 'role'은 질문 시 지정한 역할이다.\n",
        "- created : 요청한 시점의 타임스탬프이다.\n",
        "- object : 반환된 객체의 유형이다. ChatGPT의 경우 chat.completion 객체로 반환된다.\n",
        "- usage : 질문할 때 사용된 토큰 수, 응답할 때 사용한 토큰 수, 총 사용한 토큰 수를 각각 제공한다."
      ],
      "metadata": {
        "id": "z3aCoRX30lXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvFLKgE81pd7",
        "outputId": "09046a8b-6498-46c5-90af-43d1510c5a16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making a pizza involves several steps, including making the dough, preparing the sauce, adding toppings, and baking it. Here's a simple recipe for making a classic homemade pizza:\n",
            "\n",
            "Ingredients:\n",
            "- Pizza dough:\n",
            "  - 2 ½ to 3 cups all-purpose flour\n",
            "  - 1 cup warm water\n",
            "  - 1 packet (2 ¼ teaspoons) active dry yeast\n",
            "  - 1 teaspoon sugar\n",
            "  - 2 tablespoons olive oil\n",
            "  - 1 teaspoon salt\n",
            "\n",
            "- Pizza sauce:\n",
            "  - 1 can (14 ounces) crushed tomatoes\n",
            "  - 1 clove garlic, minced\n",
            "  - 1 teaspoon olive oil\n",
            "  - 1 teaspoon dried basil\n",
            "  - 1 teaspoon dried oregano\n",
            "  - Salt and pepper to taste\n",
            "\n",
            "- Toppings:\n",
            "  - Shredded mozzarella cheese\n",
            "  - Any desired toppings (e.g., sliced pepperoni, bell peppers, onions, mushrooms, etc.)\n",
            "\n",
            "Instructions:\n",
            "1. Make the dough:\n",
            "- In a small bowl, combine warm water, sugar, and yeast.\n",
            "- Let it sit for 5-10 minutes until the yeast becomes foamy.\n",
            "- In a large mixing bowl, combine 2 ½ cups of flour and salt.\n",
            "- Create a well in the center of the flour mixture and pour in the yeast mixture and olive oil.\n",
            "- Stir the ingredients together until they form a dough.\n",
            "- Gradually add in more flour if needed until the dough becomes smooth and slightly sticky.\n",
            "- Transfer the dough to a lightly floured surface and knead it for 5-7 minutes until it becomes elastic.\n",
            "- Place the dough in a greased bowl, cover it with a clean towel, and let it rise in a warm place for about 1-2 hours until it doubles in size.\n",
            "\n",
            "2. Prepare the pizza sauce:\n",
            "- In a saucepan, heat olive oil over medium heat and add minced garlic.\n",
            "- Cook for about 1 minute until garlic becomes fragrant, but be careful not to burn it.\n",
            "- Add crushed tomatoes, basil, oregano, salt, and pepper to taste.\n",
            "- Reduce the heat and let the sauce simmer for about 15-20 minutes.\n",
            "- Remove from heat and set it aside to cool.\n",
            "\n",
            "3. Assemble the pizza:\n",
            "- Preheat your oven to the highest temperature possible (usually around 500°F/260°C).\n",
            "- Punch down the risen dough and divide it into desired portions.\n",
            "- On a lightly floured surface, roll out each portion into your desired pizza shape and thickness.\n",
            "- Place the dough onto a baking sheet or a pizza stone.\n",
            "- Spread an even layer of pizza sauce onto the dough, leaving about a ½ inch border around the edges.\n",
            "- Sprinkle a generous amount of shredded mozzarella cheese over the sauce.\n",
            "- Add your desired toppings, such as pepperoni, bell peppers, onions, mushrooms, etc.\n",
            "\n",
            "4. Bake the pizza:\n",
            "- Place the pizza in the preheated oven and bake for about 10-15 minutes or until the crust is golden brown and the cheese is melted and bubbly.\n",
            "- Keep an eye on it to prevent burning.\n",
            "- Once baked, remove the pizza from the oven and let it cool for a few minutes.\n",
            "- Slice it into pieces and serve it hot.\n",
            "\n",
            "Enjoy your homemade pizza!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "소모한 토큰 수 확인"
      ],
      "metadata": {
        "id": "WX2DGuI81_GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['usage'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMpMiRZ11__c",
        "outputId": "4dc56809-73e0-4d6a-c921-04953dda3a1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"prompt_tokens\": 14,\n",
            "  \"completion_tokens\": 674,\n",
            "  \"total_tokens\": 688\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*총 비용 계산**  \n",
        "gpt-3.5-turbo 모델을 사용했고,   \n",
        "해당 모델의 프롬프트 토큰은 1000 토큰당 \\$0.0015,  \n",
        "완료 토큰은 1000토큰당 $0.002의 비용이 발생하므로 약 1.62120175원을 사용한다.  "
      ],
      "metadata": {
        "id": "undXPupw2L57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key='sk-'\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"2020년월드시리즈에서는 누가 우승했어?\"}]\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wvEIAIt3HHL",
        "outputId": "b106b903-707e-4961-e4aa-021210d854bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8aHGL6ibKd9NquSvM3EYS2gMfkFyV\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1703656857,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"2020\\ub144 \\uc6d4\\ub4dc\\uc2dc\\ub9ac\\uc988\\uc5d0\\uc11c\\ub294 \\ub85c\\uc2a4\\uc564\\uc824\\ub808\\uc2a4 \\ub2e4\\uc800\\uc2a4\\uac00 \\ud0ec\\ud30c\\ubca0\\uc774 \\ub808\\uc774\\uc2a4\\ub97c \\uc0c1\\ub300\\ub85c \\uc6b0\\uc2b9\\ud588\\uc2b5\\ub2c8\\ub2e4.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 33,\n",
            "    \"completion_tokens\": 51,\n",
            "    \"total_tokens\": 84\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuHky8-b3ajL",
        "outputId": "5e9db185-7644-490b-dc58-0931df12fe62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020년 월드시리즈에서는 로스앤젤레스 다저스가 탬파베이 레이스를 상대로 우승했습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 역할 부여하기\n",
        "\n",
        "- GhatGPT API를 이용해 ChatAPI를 사용할 때는 ChatGPT에게 역할을 지시할 수 있다.\n",
        "- 역할지시란 ChatGPT가 앞으로 답변할 때 해당 역할로서 답변이라는 의미이다.\n",
        "- 역할 지시 방법은 항상 지시한 역할대로 동작한다는 보장은 없지만, 역할 지시문에 따라 답변 자체의 방향성을 바꿔 버리기도 한다.\n",
        "- 역할을 지시하려면 기존 코드에서 {\"role\": \"system\", \"content\": \" \"}를 추가한다."
      ],
      "metadata": {
        "id": "A6KRBsg93yPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"너는 친절하고 상세하게 답변해주는 비서야.\"},\n",
        "            {\"role\": \"user\", \"content\": \"2020년 월드시리즈에서는 누가 우승했어?\"}]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juWExuy34GHY",
        "outputId": "b6ee257d-2f29-4077-c28a-cea1f57bb8bb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020년 월드시리즈에서는 로스앤젤레스 다저스(Los Angeles Dodgers)가 우승했어요. 다저스는 텍사스 레인저스(Texas Rangers)와의 7경기 시리즈에서 우승을 차지했습니다. 이로써 다저스는 1988년 이후 32년 만에 월드시리즈 우승을 차지한 것이었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"너는 초등학교 선생님이야. 초등학생도 알기 쉽게 설명해줘.\"},\n",
        "            {\"role\": \"user\", \"content\": \"2020년 월드시리즈에서는 누가 우승했어?\"}]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUYEhkj25VVi",
        "outputId": "86053345-798d-4866-8a32-80fc1c6543b2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020년 월드시리즈에서는 로스앤젤레스 다저스가 우승했어. 월드시리즈는 미국 프로 야구 메이저 리그에서 진행되는 경기로, 이번 시즌에는 로스앤젤레스 다저스가 텍사스주에 있는 글로브 라이프 파크에서 플레이오프를 거쳐 우승을 차지했어. 로스앤젤레스 다저스는 도로이스어(지금의 로스앤젤레스 다저스 볼파크)에서 처음으로 월드시리즈 우승을 한 이후로 32년만에 우승한 거야. 그들은 탬파베이 레이즈를 4승 2패로 이기고 챔피언이 됐어.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"You are a chatbot that answers questions in English even in Korean.\"},\n",
        "            {\"role\": \"user\", \"content\": \"2020년 월드시리즈에서는 누가 우승했어?\"}]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE_l4u8p51DT",
        "outputId": "07c6f28f-48f4-4fdb-fe6d-a8dab0e5b58f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020년 월드시리즈에서는 로스앤젤레스 다저스가 우승했어요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "유저의 질문에 답변을 거절하고, 사과하는 챗봇을 구현하기."
      ],
      "metadata": {
        "id": "j7Hbrk8a7K6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"You are a chatbot that refuses to answer and says sorry when users ask questions.\"},\n",
        "            {\"role\": \"user\", \"content\": \"2020년 월드시리즈에서는 누가 우승했어?\"}]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSV1Blst6ydy",
        "outputId": "fa2ed6a0-ccae-48a8-b43d-8caa3758a988"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I am unable to answer that question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"You are a chatbot in Korean that refuses to answer and says sorry when users ask questions.\"},\n",
        "            {\"role\": \"user\", \"content\": \"2020년 월드시리즈에서는 누가 우승했어?\"}]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y69mCGJV8mnc",
        "outputId": "cb05b092-637d-43f3-b866-e7eb0b4f473e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "죄송합니다, 질문에는 대답할 수 없습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "유저의 질문을 영어로 번역하여 답변하기."
      ],
      "metadata": {
        "id": "WQBdG5_g8ge3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"You are a translator woh translates user input.\"},\n",
        "            {\"role\": \"user\", \"content\": \"2020년 월드시리즈에서는 누가 우승했어?\"}]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q645Cnzs8XRi",
        "outputId": "f3514002-cb6a-42cb-adbc-6a9a97c64762"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who won the World Series in 2020?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 이전대화를 포함하여 답변하기\n",
        "\n",
        "- ChatGPT는 답변할 때 이전 질문과 답변을 모두 고려하여 답변하는 특징이 있다.  \n",
        "- ChatGPT API를 이용하면 ChatGPT에게 답변을 요청할 때 '앞서 네가 이런 답변을 한 상태였다'라는 정보를 전달할 수 있다. 이것은 사용자가 가정하는 것이지만, ChatGPT는 마치 과거에 자신이 답변한 것으로 가정하고, 추가 답변을 제공한다.  \n",
        "-  mesages=[ ]안에  {'role': 'user', 'content':' '}작성 후 {'role':'assistant', 'content':' '}을 추가로 작성하고, 다시 {'role':'user', 'content':' '}를 번갈아 작성하면 된다."
      ],
      "metadata": {
        "id": "nwLGj0b99OtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"2002년 월드컵에서 가장 화제가 되었던 나라는 어디야?\"}]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwd5I2o39hGo",
        "outputId": "be60e2a1-3b50-4b1c-a127-5b209038d720"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2002년 월드컵에서 가장 화제가 된 나라는 한국이었습니다. 한국은 월드컵 역사상 처음으로 4강에 진출한 아시아 국가로서 전 세계의 관심을 받았습니다. 한국은 동계올림픽과 함께 세계체전 역사상 최고의 행적을 보인 나라로 평가받기도 했습니다. 이러한 성과로 인해 한국은 공식적인 월드컵 호스트로서 2002년 대회를 개최하게 되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"2002년 월드컵에서 가장 화제가 되었던 나라는 어디야?\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"2002년 월드컵에서 가장 화제가 된 나라는 한국이었습니다. 한국은 월드컵 역사상 처음으로 4강에 진출한 아시아 국가로서 전 세계의 관심을 받았습니다. 한국은 동계올림픽과 함께 세계체전 역사상 최고의 행적을 보인 나라로 평가받기도 했습니다. 이러한 성과로 인해 한국은 공식적인 월드컵 호스트로서 2002년 대회를 개최하게 되었습니다.\"},\n",
        "            {\"role\": \"user\", \"content\": \"그 나라가 화제가 되었던 이유를 자세하게 설명해줘.\"}]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWJSsTfZ9YN4",
        "outputId": "d8b841ce-ad4b-4a8f-ee8d-ceeeee7d5523"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국이 2002년 월드컵에서 화제가 된 이유는 몇 가지가 있습니다.\n",
            "\n",
            "첫째, 한국은 월드컵 역사상 처음으로 4강에 진출한 아시아 국가였습니다. 이는 그동안 강호로 알려진 유럽과 남미 국가들에 의해 석권되었던 월드컵에서 아시아 국가의 역사적인 돌파구였습니다. 한국은 흥분된 홈 경기 환경과 신체적인 강점을 살려 흥미진진한 경기를 펼치며 세계에서 큰 주목을 받았습니다.\n",
            "\n",
            "둘째, 한국의 성과는 일각에서는 호스트 국가 유리한 조작이 일어났다는 의혹을 일으켰습니다. 경기에서의 화끈한 선수들의 플레이, 부정적인 심판 결정 등이 토론거리가 되었으며, 특히 한국이 이탈리아와의 경기에서 이기는 데에 있어 심판판정이 논란을 일으키기도 했습니다.\n",
            "\n",
            "셋째, 한국인들의 열정과 응원도 큰 화제가 되었습니다. 한국인들은 월드컵을 성취적이고 흥미로운 사건으로 바라보았으며, 경기장에서는 환호와 응원으로 가득 찼습니다. 이러한 열정적인 응원은 세계에서 큰 경이와 찬사를 받았으며, 한국의 호스트 국가로서의 역할을 수행하는데 큰 영향을 미쳤습니다.\n",
            "\n",
            "이와 같은 이유들로 인해 2002년 월드컵에서는 한국이 화제의 중심이 되었으며, 아시아 국가의 축구 역사상 중요한 이정표로 남았습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"인공지능에 대해서 알려줘.\"}]\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR4IZVCcDcwh",
        "outputId": "8b4bb1df-e0ec-4eab-f431-2059abfc7078"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8aI6nXoHoWTgnLGqnNiTuypY2ceBX\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1703660109,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"\\uc778\\uacf5\\uc9c0\\ub2a5(Artificial Intelligence, AI)\\uc740 \\uc778\\uac04\\uc758 \\uc9c0\\ub2a5\\uc744 \\ubaa8\\ubc29\\ud558\\uac70\\ub098 \\ub300\\uccb4\\ud558\\ub294 \\ucef4\\ud4e8\\ud130 \\uc2dc\\uc2a4\\ud15c\\uc774\\ub098 \\ud504\\ub85c\\uadf8\\ub7a8\\uc744 \\ub73b\\ud569\\ub2c8\\ub2e4. \\uc774\\ub294 \\ucef4\\ud4e8\\ud130\\uac00 \\uc0ac\\uace0, \\ud559\\uc2b5, \\ubb38\\uc81c \\ud574\\uacb0 \\ub4f1\\uc758 \\ub2a5\\ub825\\uc744 \\uac16\\ucd94\\uac8c \\ud558\\ub294 \\uae30\\uc220\\uc774\\uba70, \\uc8fc\\ub85c \\uae30\\uacc4 \\ud559\\uc2b5, \\uc790\\uc5f0\\uc5b4 \\ucc98\\ub9ac, \\ucef4\\ud4e8\\ud130 \\ube44\\uc804, \\ub85c\\ubd07 \\uacf5\\ud559 \\ub4f1 \\ub2e4\\uc591\\ud55c \\ubd84\\uc57c\\uc5d0\\uc11c \\ud65c\\uc6a9\\ub429\\ub2c8\\ub2e4.\\n\\n\\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\uae30\\uacc4 \\ud559\\uc2b5(Machine Learning)\\uacfc \\ub525 \\ub7ec\\ub2dd(Deep Learning)\\uc744 \\ud1b5\\ud574 \\ub370\\uc774\\ud130\\ub97c \\ubd84\\uc11d\\ud558\\uace0 \\ud559\\uc2b5\\ud558\\uc5ec \\ud328\\ud134\\uc744 \\uc778\\uc2dd\\ud558\\uac70\\ub098 \\uc608\\uce21\\ud558\\ub294 \\ub2a5\\ub825\\uc744 \\uac16\\ucd94\\uac8c \\ub429\\ub2c8\\ub2e4. \\uc774\\ub97c \\ud1b5\\ud574 \\uc778\\uacf5\\uc9c0\\ub2a5 \\uc2dc\\uc2a4\\ud15c\\uc740 \\uc5d0 \\uc751\\uc6a9\\ub418\\uc5b4 \\ub2e4\\uc591\\ud55c \\uc791\\uc5c5\\uc744 \\uc218\\ud589\\ud560 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\uc608\\ub97c \\ub4e4\\uba74, \\uc74c\\uc131 \\uc778\\uc2dd, \\uc774\\ubbf8\\uc9c0 \\ubd84\\uc11d, \\uc790\\uc728\\uc8fc\\ud589, \\ucd94\\ucc9c \\uc2dc\\uc2a4\\ud15c \\ub4f1\\uc774 \\uc778\\uacf5\\uc9c0\\ub2a5\\uc774 \\uc801\\uc6a9\\ub41c \\ubd84\\uc57c\\uc785\\ub2c8\\ub2e4.\\n\\n\\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\ud604\\uc7ac \\ub9ce\\uc740 \\ubd84\\uc57c\\uc5d0\\uc11c \\uc0ac\\ub78c\\ub4e4\\uc758 \\uc0dd\\ud65c\\uacfc \\uc5c5\\ubb34\\uc5d0 \\ud070 \\uc601\\ud5a5\\uc744 \\ubbf8\\uce58\\uace0 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\uc608\\ub97c \\ub4e4\\uc5b4, \\uac80\\uc0c9 \\uc5d4\\uc9c4, \\uc74c\\uc131 \\ube44\\uc11c, \\uc5b8\\uc5b4 \\ubc88\\uc5ed, \\uc74c\\uc545 \\ucd94\\ucc9c, \\ud654\\uc7ac \\uc608\\ubc29 \\ub4f1 \\ub2e4\\uc591\\ud55c \\ubd84\\uc57c\\uc5d0\\uc11c \\uc6b0\\ub9ac\\uc758 \\uc77c\\uc0c1\\uc0dd\\ud65c\\uc5d0 \\uc9c4\\uc785\\ud558\\uace0 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\ub610\\ud55c \\uc790\\ub3d9\\ud654, \\ud6a8\\uc728\\ud654, \\uc608\\uce21 \\ubaa8\\ub378\\ub9c1, \\uc704\\ud5d8 \\ud3c9\\uac00 \\ub4f1\\uacfc \\uac19\\uc740 \\uc5c5\\ubb34\\uc5d0\\ub3c4 \\ub110\\ub9ac \\ud65c\\uc6a9\\ub418\\uace0 \\uc788\\uc2b5\\ub2c8\\ub2e4.\\n\\n\\uc778\\uacf5\\uc9c0\\ub2a5\\uc758 \\ubc1c\\uc804\\uc740 \\uacc4\\uc18d\\ub418\\uace0 \\uc788\\uc73c\\uba70, \\uc55e\\uc73c\\ub85c \\ub354 \\ub9ce\\uc740 \\ubd84\\uc57c\\uc5d0\\uc11c \\uc778\\uac04\\uc758 \\uc5c5\\ubb34\\ub97c \\ubcf4\\uc870\\ud558\\uac70\\ub098 \\ub300\\uccb4\\ud560 \\uac83\\uc73c\\ub85c \\uc608\\uce21\\ub429\\ub2c8\\ub2e4. \\uadf8\\ub7ec\\ub098 \\ub3d9\\uc2dc\\uc5d0 \\uc724\\ub9ac, \\uac1c\\uc778\\uc815\\ubcf4 \\ubcf4\\ud638, \\uc548\\uc804 \\ub4f1\\uacfc \\uad00\\ub828\\ub41c \\ubb38\\uc81c\\uc5d0 \\ub300\\ud574\\uc11c\\ub3c4 \\uc2e0\\uc911\\ud55c \\uc811\\uadfc\\uc774 \\ud544\\uc694\\ud569\\ub2c8\\ub2e4. \\uc801\\uc808\\ud55c \\uaddc\\uc81c\\uc640 \\ud1b5\\uc81c\\ub97c \\ud1b5\\ud574 \\uc778\\uacf5\\uc9c0\\ub2a5\\uc774 \\uc0ac\\ud68c\\uc801\\uc73c\\ub85c \\uc720\\uc775\\ud558\\uace0 \\uc548\\uc804\\ud558\\uac8c \\ubc1c\\uc804\\ud560 \\uc218 \\uc788\\ub3c4\\ub85d \\uad00\\ub9ac\\ub418\\uc5b4\\uc57c \\ud569\\ub2c8\\ub2e4.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 21,\n",
            "    \"completion_tokens\": 611,\n",
            "    \"total_tokens\": 632\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"인공지능에 대해서 알려줘.\"}],\n",
        "  temperature=0,\n",
        "  max_tokens=500\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alIuHnZvDtbU",
        "outputId": "c1e93bf5-9926-4854-9136-229347868721"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8aI87t0ufoCJHjx8JQ7Xl5fqsD2qQ\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1703660191,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"\\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\uc778\\uac04\\uc758 \\uc9c0\\ub2a5\\uc744 \\ubaa8\\ubc29\\ud558\\uac70\\ub098 \\ub300\\uccb4\\ud558\\uae30 \\uc704\\ud574 \\uac1c\\ubc1c\\ub41c \\ucef4\\ud4e8\\ud130 \\uc2dc\\uc2a4\\ud15c\\uc774\\ub2e4. \\uc774\\ub7ec\\ud55c \\uc2dc\\uc2a4\\ud15c\\uc740 \\ub370\\uc774\\ud130\\ub97c \\ubd84\\uc11d\\ud558\\uace0 \\ud328\\ud134\\uc744 \\ud559\\uc2b5\\ud558\\uc5ec \\ubb38\\uc81c\\ub97c \\ud574\\uacb0\\ud558\\uac70\\ub098 \\uacb0\\uc815\\uc744 \\ub0b4\\ub9b4 \\uc218 \\uc788\\ub2e4. \\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\ub2e4\\uc591\\ud55c \\ubd84\\uc57c\\uc5d0\\uc11c \\ud65c\\uc6a9\\ub418\\uba70, \\uc74c\\uc131\\uc778\\uc2dd, \\uc774\\ubbf8\\uc9c0 \\uc778\\uc2dd, \\uc790\\uc728\\uc8fc\\ud589 \\ub4f1 \\ub2e4\\uc591\\ud55c \\uae30\\uc220\\uacfc \\uc751\\uc6a9\\ubd84\\uc57c\\uac00 \\uc788\\ub2e4.\\n\\n\\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\ud06c\\uac8c \\uc57d\\ud55c \\uc778\\uacf5\\uc9c0\\ub2a5\\uacfc \\uac15\\ud55c \\uc778\\uacf5\\uc9c0\\ub2a5\\uc73c\\ub85c \\ub098\\ub25c\\ub2e4. \\uc57d\\ud55c \\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\ud2b9\\uc815\\ud55c \\uc791\\uc5c5\\uc5d0 \\ud55c\\uc815\\ub418\\uc5b4 \\ub3d9\\uc791\\ud558\\uba70, \\uc608\\ub97c \\ub4e4\\uc5b4 \\uc74c\\uc131\\uc778\\uc2dd \\uae30\\uc220\\uc774\\ub098 \\ucd94\\ucc9c \\uc54c\\uace0\\ub9ac\\uc998 \\ub4f1\\uc774 \\uc788\\ub2e4. \\uac15\\ud55c \\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\uc778\\uac04\\uacfc \\uac70\\uc758 \\ub3d9\\uc77c\\ud55c \\uc218\\uc900\\uc758 \\uc9c0\\ub2a5\\uc744 \\uac00\\uc9c0\\uba70, \\ub2e4\\uc591\\ud55c \\uc791\\uc5c5\\uc744 \\uc218\\ud589\\ud560 \\uc218 \\uc788\\ub2e4. \\ud604\\uc7ac\\uae4c\\uc9c0\\ub294 \\uac15\\ud55c \\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\uc544\\uc9c1 \\uac1c\\ubc1c\\ub418\\uc9c0 \\uc54a\\uc558\\uc73c\\uba70, \\uc5f0\\uad6c\\uc640 \\uac1c\\ubc1c\\uc774 \\uc9c4\\ud589 \\uc911\\uc774\\ub2e4.\\n\\n\\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\uba38\\uc2e0\\ub7ec\\ub2dd, \\ub525\\ub7ec\\ub2dd, \\uac15\\ud654\\ud559\\uc2b5 \\ub4f1\\uc758 \\ub2e4\\uc591\\ud55c \\uae30\\uc220\\uacfc \\uc54c\\uace0\\ub9ac\\uc998\\uc744 \\uc0ac\\uc6a9\\ud558\\uc5ec \\uad6c\\ud604\\ub41c\\ub2e4. \\uba38\\uc2e0\\ub7ec\\ub2dd\\uc740 \\ub370\\uc774\\ud130\\ub97c \\uae30\\ubc18\\uc73c\\ub85c \\ud328\\ud134\\uc744 \\ud559\\uc2b5\\ud558\\uace0 \\uc608\\uce21\\ud558\\ub294 \\uae30\\uc220\\uc774\\uba70, \\ub525\\ub7ec\\ub2dd\\uc740 \\uc778\\uacf5\\uc2e0\\uacbd\\ub9dd\\uc744 \\uc0ac\\uc6a9\\ud558\\uc5ec \\ubcf5\\uc7a1\\ud55c \\ubb38\\uc81c\\ub97c \\ud574\\uacb0\\ud558\\ub294 \\uae30\\uc220\\uc774\\ub2e4. \\uac15\\ud654\\ud559\\uc2b5\\uc740 \\uc2dc\\ud589\\ucc29\\uc624\\ub97c \\ud1b5\\ud574 \\ud559\\uc2b5\\ud558\\uba70 \\ubcf4\\uc0c1\\uc744 \\ucd5c\\ub300\\ud654\\ud558\\ub294 \\ubc29\\ud5a5\\uc73c\\ub85c \\ud559\\uc2b5\\ud558\\ub294 \\uae30\\uc220\\uc774\\ub2e4.\\n\\n\\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\ud604\\uc7ac \\ub9ce\\uc740 \\ubd84\\uc57c\\uc5d0\\uc11c \\ud65c\\uc6a9\\ub418\\uace0 \\uc788\\uc73c\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 21,\n",
            "    \"completion_tokens\": 500,\n",
            "    \"total_tokens\": 521\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GufgwlllEJt2",
        "outputId": "c6ad24c1-cead-4614-9aeb-fc31f420238c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능은 인간의 지능을 모방하거나 대체하기 위해 개발된 컴퓨터 시스템이다. 이러한 시스템은 데이터를 분석하고 패턴을 학습하여 문제를 해결하거나 결정을 내릴 수 있다. 인공지능은 다양한 분야에서 활용되며, 음성인식, 이미지 인식, 자율주행 등 다양한 기술과 응용분야가 있다.\n",
            "\n",
            "인공지능은 크게 약한 인공지능과 강한 인공지능으로 나뉜다. 약한 인공지능은 특정한 작업에 한정되어 동작하며, 예를 들어 음성인식 기술이나 추천 알고리즘 등이 있다. 강한 인공지능은 인간과 거의 동일한 수준의 지능을 가지며, 다양한 작업을 수행할 수 있다. 현재까지는 강한 인공지능은 아직 개발되지 않았으며, 연구와 개발이 진행 중이다.\n",
            "\n",
            "인공지능은 머신러닝, 딥러닝, 강화학습 등의 다양한 기술과 알고리즘을 사용하여 구현된다. 머신러닝은 데이터를 기반으로 패턴을 학습하고 예측하는 기술이며, 딥러닝은 인공신경망을 사용하여 복잡한 문제를 해결하는 기술이다. 강화학습은 시행착오를 통해 학습하며 보상을 최대화하는 방향으로 학습하는 기술이다.\n",
            "\n",
            "인공지능은 현재 많은 분야에서 활용되고 있으\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''한국어를 영어로 번역해줘.\n",
        "           한국어 : 나는 사람이다.\n",
        "           영어 : '''\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "  temperature=0,\n",
        "  max_tokens=500\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cozN8wcEQh-",
        "outputId": "6aa2cba8-9632-4697-d322-d84d6094865c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am a person.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''sklearn에서 제공해주는 titanic데이터프레임을 이용해서 남여 생존을 분석하는 프로그램을 파이썬으로 구현해줘.'''\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "  temperature=0,\n",
        "  max_tokens=500\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICRMzQHxDy3f",
        "outputId": "9e3a7de8-f2ba-4947-aadf-00da02143011"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아래는 sklearn에서 제공하는 titanic 데이터프레임을 이용하여 남여 생존을 분석하는 파이썬 프로그램입니다.\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.tree import DecisionTreeClassifier\n",
            "from sklearn.metrics import accuracy_score\n",
            "\n",
            "# titanic 데이터프레임 로드\n",
            "from sklearn.datasets import fetch_openml\n",
            "titanic = fetch_openml('titanic', version=1, as_frame=True)\n",
            "df = titanic.data\n",
            "df['target'] = titanic.target\n",
            "\n",
            "# 필요한 열 선택\n",
            "df = df[['sex', 'age', 'fare', 'target']]\n",
            "\n",
            "# 결측치 처리\n",
            "df = df.dropna()\n",
            "\n",
            "# 성별을 숫자로 변환\n",
            "df['sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
            "\n",
            "# 입력과 타겟 데이터로 분리\n",
            "X = df[['sex', 'age', 'fare']]\n",
            "y = df['target']\n",
            "\n",
            "# 학습 데이터와 테스트 데이터로 분리\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "# 의사결정트리 모델 생성 및 학습\n",
            "model = DecisionTreeClassifier()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# 테스트 데이터로 예측\n",
            "y_pred = model.predict(X_test)\n",
            "\n",
            "# 정확도 출력\n",
            "accuracy = accuracy_score(y_test, y_pred)\n",
            "print(\"Accuracy:\", accuracy)\n",
            "```\n",
            "\n",
            "위의 코드는 titanic 데이터프레임을 로드하고, 필요한 열을 선택한 후 결측치를 처리합니다. 그리고 성별을 숫자로 변환하고 입력과 타겟 데이터로 분리합니다. 학습 데이터와 테스트 데이터로 분리한 후 의사결정트리 모델을 생성하고 학습시킵니다. 마지막으로 테스트 데이터로 예측을 수행하고 정확도를 출력합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 데이터셋 로드\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# 성별과 생존 여부만 선택\n",
        "df = df[['sex', 'target']]\n",
        "\n",
        "# 성별을 숫자로 변환 (남성: 0, 여성: 1)\n",
        "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# 데이터셋 분리\n",
        "X = df[['sex']]\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 의사결정트리 모델 생성 및 학습\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 정확도 출력\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Q5k0xW4dGQOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# titanic 데이터프레임 로드\n",
        "from sklearn.datasets import fetch_openml\n",
        "titanic = fetch_openml('titanic', version=1, as_frame=True)\n",
        "df = titanic.data\n",
        "df['target'] = titanic.target\n",
        "\n",
        "# 필요한 열 선택\n",
        "df = df[['sex', 'age', 'fare', 'target']]\n",
        "\n",
        "# 결측치 처리\n",
        "df = df.dropna()\n",
        "\n",
        "# 성별을 숫자로 변환\n",
        "df['sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
        "\n",
        "# 입력과 타겟 데이터로 분리\n",
        "X = df[['sex', 'age', 'fare']]\n",
        "y = df['target']\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 의사결정트리 모델 생성 및 학습\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 정확도 출력\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxaEZBjDGmUY",
        "outputId": "09cda039-05fc-4ee4-add5-ffe610277697"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.69377990430622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "cHOV9K2YHVSO",
        "outputId": "14a84df0-fdca-4f24-9a32-83f9f4d461c5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   pclass                                             name     sex      age  \\\n",
              "0     1.0                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
              "1     1.0                   Allison, Master. Hudson Trevor    male   0.9167   \n",
              "2     1.0                     Allison, Miss. Helen Loraine  female   2.0000   \n",
              "3     1.0             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
              "4     1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
              "\n",
              "   sibsp  parch  ticket      fare    cabin embarked  boat   body  \\\n",
              "0    0.0    0.0   24160  211.3375       B5        S     2   None   \n",
              "1    1.0    2.0  113781  151.5500  C22 C26        S    11    NaN   \n",
              "2    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
              "3    1.0    2.0  113781  151.5500  C22 C26        S  None  135.0   \n",
              "4    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
              "\n",
              "                         home.dest target  \n",
              "0                     St Louis, MO      1  \n",
              "1  Montreal, PQ / Chesterville, ON      1  \n",
              "2  Montreal, PQ / Chesterville, ON      0  \n",
              "3  Montreal, PQ / Chesterville, ON      0  \n",
              "4  Montreal, PQ / Chesterville, ON      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c08fb127-9629-40b6-ba83-8aaea6a2456e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>name</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>ticket</th>\n",
              "      <th>fare</th>\n",
              "      <th>cabin</th>\n",
              "      <th>embarked</th>\n",
              "      <th>boat</th>\n",
              "      <th>body</th>\n",
              "      <th>home.dest</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Allen, Miss. Elisabeth Walton</td>\n",
              "      <td>female</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24160</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>B5</td>\n",
              "      <td>S</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>St Louis, MO</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Allison, Master. Hudson Trevor</td>\n",
              "      <td>male</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Allison, Miss. Helen Loraine</td>\n",
              "      <td>female</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
              "      <td>male</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>None</td>\n",
              "      <td>135.0</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
              "      <td>female</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c08fb127-9629-40b6-ba83-8aaea6a2456e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c08fb127-9629-40b6-ba83-8aaea6a2456e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c08fb127-9629-40b6-ba83-8aaea6a2456e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37f5c0b0-8a4d-46ca-af07-116f6cbf6332\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37f5c0b0-8a4d-46ca-af07-116f6cbf6332')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37f5c0b0-8a4d-46ca-af07-116f6cbf6332 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHFELK6WIwBN",
        "outputId": "8549b0c8-f673-497b-b699-a49689cf9104"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    809\n",
              "1    500\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''data변수에 저장된 문자열의 길이를 구하는 프로그램을 자바로 구현해줘.'''\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "  temperature=0,\n",
        "  max_tokens=500\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUW5V0rUIEnu",
        "outputId": "289652c0-2da9-4ab9-951a-3fd451d01909"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아래는 주어진 문자열의 길이를 구하는 자바 프로그램입니다.\n",
            "\n",
            "```java\n",
            "public class Main {\n",
            "    public static void main(String[] args) {\n",
            "        String data = \"Hello, World!\";\n",
            "        int length = data.length();\n",
            "        System.out.println(\"문자열의 길이: \" + length);\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "위 프로그램은 \"Hello, World!\"라는 문자열의 길이를 구하는 예시입니다. `data.length()` 메소드를 사용하여 문자열의 길이를 구하고, `System.out.println()` 메소드를 사용하여 결과를 출력합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jGF7RqOVI5YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''자바와 오라클을 연동해서 오라클의 employees의 데이터를 자바에서 가져와서 출력해주는 프로그램을 구현해줘.'''\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "  temperature=0,\n",
        "  max_tokens=500\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rj1Mh8IIhSW",
        "outputId": "a92e283e-182f-4235-d8c5-e54e5bb200e0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아래는 자바와 오라클을 연동하여 employees 테이블의 데이터를 가져와서 출력하는 예제입니다.\n",
            "\n",
            "```java\n",
            "import java.sql.*;\n",
            "\n",
            "public class OracleConnectionExample {\n",
            "    public static void main(String[] args) {\n",
            "        // 오라클 데이터베이스 연결 정보\n",
            "        String url = \"jdbc:oracle:thin:@localhost:1521:xe\";\n",
            "        String username = \"사용자명\";\n",
            "        String password = \"비밀번호\";\n",
            "\n",
            "        // JDBC 드라이버 로드\n",
            "        try {\n",
            "            Class.forName(\"oracle.jdbc.driver.OracleDriver\");\n",
            "        } catch (ClassNotFoundException e) {\n",
            "            e.printStackTrace();\n",
            "        }\n",
            "\n",
            "        // 데이터베이스 연결\n",
            "        try (Connection conn = DriverManager.getConnection(url, username, password)) {\n",
            "            // SQL 쿼리 작성\n",
            "            String sql = \"SELECT * FROM employees\";\n",
            "\n",
            "            // SQL 쿼리 실행\n",
            "            try (Statement stmt = conn.createStatement();\n",
            "                 ResultSet rs = stmt.executeQuery(sql)) {\n",
            "                // 결과 출력\n",
            "                while (rs.next()) {\n",
            "                    int employeeId = rs.getInt(\"employee_id\");\n",
            "                    String firstName = rs.getString(\"first_name\");\n",
            "                    String lastName = rs.getString(\"last_name\");\n",
            "                    String email = rs.getString(\"email\");\n",
            "                    System.out.println(\"Employee ID: \" + employeeId);\n",
            "                    System.out.println(\"First Name: \" + firstName);\n",
            "                    System.out.println(\"Last Name: \" + lastName);\n",
            "                    System.out.println(\"Email: \" + email);\n",
            "                    System.out.println(\"--------------------\");\n",
            "                }\n",
            "            }\n",
            "        } catch (SQLException e) {\n",
            "            e.printStackTrace();\n",
            "        }\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "위의 코드에서 \"사용자명\"과 \"비밀번호\" 부분을 실제 오라클 데이터베이스의 사용자명과 비밀번호로 변경해야 합니다. 또한, `jdbc:oracle:thin:@localhost:1521:xe` 부분은 실제 오라클 데이터베이스의 URL로 변경해야 합니다.\n",
            "\n",
            "위의 코드를 실행하면 employees 테이블의 데이터가 자바에서 가져와서 출력됩니다.\n"
          ]
        }
      ]
    }
  ]
}