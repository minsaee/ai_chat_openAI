{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR/IheEZJqmBeQoMRoXjqj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsaee/ai_chat_openAI/blob/master/005_kakaobot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pZuU-sxGZpQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/MyDrive/ai_chat_openAI'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastAPI를 활용해서 로컬서버 생성하기."
      ],
      "metadata": {
        "id": "QqsvqDeDGuau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이썬 기반의 웹 서버 생성 오픈소스\n",
        "!pip install fastapi\n",
        "\n",
        "# 비동기 서버 추가 생성 'uvicorn'\n",
        "!pip install 'uvicorn[standard]'\n",
        "\n",
        "!pip install pyngrok\n",
        "\n",
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "id": "YXvx6oNhGi5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kakaobot.py\n",
        "from fastapi import Request, FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root ():\n",
        "  return {\"message\":\"KakaoTest\"}\n",
        "\n",
        "@app.post('/chat/')\n",
        "async def chat(request:Request):\n",
        "  kakaorequest = await request.json()\n",
        "  print(kakaorequest)\n",
        "  return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZKmUhUQHQpl",
        "outputId": "f07f2510-913a-43c3-af21-202d5d91d4f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kakaobot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=8000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# !uvicorn/content/drive/MyDrive/ai_chat_openAI/kakaobot:app --reload --server.port=8000\n",
        "!uvicorn kakaobot:app --reload"
      ],
      "metadata": {
        "id": "4NW_GNZaHe0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. FastAPI 로컬서버 구현\n",
        "2. Ngrok으로 로컬서버 외부에서 접속할 수 있도록 구현\n",
        "3. 챗봇생성(챗지피티API마스터)\n",
        "4. 챗봇구현"
      ],
      "metadata": {
        "id": "kdcU5vPrSI_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 기본설정단계\n",
        "   - 프로그램이 사용하는 패키지를 불러오고 OpenAPI의 API키를 지정한다.\n",
        "2.  기능 함수 구현 단계\n",
        "   - 프로그램의 모든 기능을 함수화하여 메인 함수에서 사용할 수 있게 정리한다.\n",
        "3. 서버 생성단계\n",
        "   - FastAPI를 활용하여 로컬 서버를 생성한다.\n",
        "4. 메인 함수 구현 단계\n",
        "   - 프로그램을 구동하는 메인함수로 상황에 맞는 함수를 호출하여 코드를 진행한다."
      ],
      "metadata": {
        "id": "Zp-MbmnVaEbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile kakaobot.py\n",
        "### 1. 기본 정보 설정\n",
        "from fastapi import Request, FastAPI\n",
        "import openai\n",
        "import threading\n",
        "import time\n",
        "import queue as q\n",
        "import os\n",
        "\n",
        "API_KEY = 'sk-'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "### 2. 기능 함수 구현\n",
        "\n",
        "## 2-1. ChatGPT에게 질문/답변 받기\n",
        "def getTextFromGPT(prompt):\n",
        "  messages_prompt = [{\"role\":\"system\",\n",
        "                     \"content\":'You are a thoughtful assistant. Respond to all input in 25 words and answer in korea'}]\n",
        "  messages_prompt += [{'role':'user', 'content':prompt}]\n",
        "  response = openai.ChatCompletion.create(model = 'gpt-3.5-turbo', messages=messages_prompt)\n",
        "  message = response['choices'][0]['message']['content']\n",
        "  return message\n",
        "\n",
        "# result = getTextFromGPT('빨강은 영어로?')\n",
        "# print(result) 빨강은 영어로는 \"red\"입니다.\n",
        "\n",
        "## 2-2. ChatGPT의 답변을 카카오톡 서버로 전달하기\n",
        "\n",
        "def textResponseFormat(bot_response):\n",
        "  response = {'version':'2.0',\n",
        "              'template':{'outputs':[{'simpleText':{'text':bot_response}}], 'quickReplies':[]}}\n",
        "  return response\n",
        "\n",
        "## 2-3 답변 요청 및 응답 확인 함수\n",
        "def responseOpenAI(request, response_queue, filename):\n",
        "  response_message = getTextFromGPT(request)\n",
        "  print(response_message)\n",
        "\n",
        "### 3. 서버 생성\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root ():\n",
        "  return {\"message\":\"KakaoTest\"}\n",
        "\n",
        "@app.post('/chat/')\n",
        "async def chat(request:Request):\n",
        "  kakaorequest = await request.json()\n",
        "  print(kakaorequest)\n",
        "  return mainChat(kakaorequest)\n",
        "\n",
        "### 4. 메인 함수 구현\n",
        "\n",
        "## 4-1. 메인 함수\n",
        "def mainChat(kakaorequest):\n",
        "  run_flag = False\n",
        "  start_time = time.time()\n",
        "\n",
        "  # 응답 결과를 저장하기 위한 텍스트 파일 생성\n",
        "  cwd = os.getcwd()\n",
        "  filename = cwd + './log/botlog.txt'\n",
        "  if not os.path.exists(filename):\n",
        "    with open(filename, 'w') as f:\n",
        "      f.write('')\n",
        "  else:\n",
        "    print('File Exists')\n",
        "\n",
        "  # 답변 생성 함수 실행\n",
        "  response_queue = q.Queue()\n",
        "  request_response = threading.Thread(target=responseOpenAI, args=(kakaorequest, response_queue, filename))\n",
        "  request_response.start() # 스레드 실행\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc3gDe6sZnLI",
        "outputId": "8d164ce9-53f9-4b31-bb40-02ebf1c29d37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빨강은 영어로는 \"red\"입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kakaobot.py\n",
        "###### 기본 정보 설정 단계 #######\n",
        "from fastapi import Request, FastAPI\n",
        "import openai\n",
        "import threading\n",
        "import time\n",
        "import queue as q\n",
        "import os\n",
        "\n",
        "# OpenAI API KEY\n",
        "API_KEY = 'sk-'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "###### 기능 구현 단계 #######\n",
        "\n",
        "# 메세지 전송\n",
        "def textResponseFormat(bot_response):\n",
        "    response = {'version': '2.0', 'template': {\n",
        "    'outputs': [{\"simpleText\": {\"text\": bot_response}}], 'quickReplies': []}}\n",
        "    return response\n",
        "\n",
        "# 사진 전송\n",
        "def imageResponseFormat(bot_response,prompt):\n",
        "    output_text = prompt+\"내용에 관한 이미지 입니다\"\n",
        "    response = {'version': '2.0', 'template': {\n",
        "    'outputs': [{\"simpleImage\": {\"imageUrl\": bot_response,\"altText\":output_text}}], 'quickReplies': []}}\n",
        "    return response\n",
        "\n",
        "# 응답 초과시 답변\n",
        "def timeover():\n",
        "    response = {\"version\":\"2.0\",\"template\":{\n",
        "      \"outputs\":[\n",
        "         {\n",
        "            \"simpleText\":{\n",
        "               \"text\":\"아직 제가 생각이 끝나지 않았어요🙏🙏\\n잠시후 아래 말풍선을 눌러주세요👆\"\n",
        "            }\n",
        "         }\n",
        "      ],\n",
        "      \"quickReplies\":[\n",
        "         {\n",
        "            \"action\":\"message\",\n",
        "            \"label\":\"생각 다 끝났나요?🙋\",\n",
        "            \"messageText\":\"생각 다 끝났나요?\"\n",
        "         }]}}\n",
        "    return response\n",
        "\n",
        "# ChatGPT에게 질문/답변 받기\n",
        "def getTextFromGPT(prompt):\n",
        "    messages_prompt = [{\"role\": \"system\", \"content\": 'You are a thoughtful assistant. Respond to all input in 25 words'}]\n",
        "    messages_prompt += [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages_prompt)\n",
        "    message = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return message\n",
        "\n",
        "# DALLE.2에게 질문/그림 URL 받기\n",
        "def getImageURLFromDALLE(prompt):\n",
        "    response = openai.Image.create(prompt=prompt,n=1,size=\"512x512\")\n",
        "    print('image response:', response)\n",
        "    image_url = response['data'][0]['url']\n",
        "    return image_url\n",
        "\n",
        "# 텍스트파일 초기화\n",
        "def dbReset(filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"\")\n",
        "\n",
        "###### 서버 생성 단계 #######\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"kakaoTest\"}\n",
        "\n",
        "@app.post(\"/chat/\")\n",
        "async def chat(request: Request):\n",
        "    kakaorequest = await request.json()\n",
        "    print('kakaorequest:', kakaorequest)\n",
        "    return mainChat(kakaorequest)\n",
        "\n",
        "###### 메인 함수 단계 #######\n",
        "\n",
        "# 메인 함수\n",
        "def mainChat(kakaorequest):\n",
        "\n",
        "    run_flag = False\n",
        "    start_time = time.time()\n",
        "\n",
        "    # 응답 결과를 저장하기 위한 텍스트 파일 생성\n",
        "    cwd = os.getcwd()\n",
        "    filename = cwd + '/log/botlog.txt'\n",
        "    if not os.path.exists(filename):\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(\"\")\n",
        "    else:\n",
        "        print(\"File Exists\")\n",
        "\n",
        "    # 답변 생성 함수 실행\n",
        "    response_queue = q.Queue()\n",
        "    request_respond = threading.Thread(target=responseOpenAI,\n",
        "                                        args=(kakaorequest, response_queue,filename))\n",
        "    request_respond.start()\n",
        "\n",
        "    # 답변 생성 시간 체크\n",
        "    while (time.time() - start_time < 3.5):\n",
        "        if not response_queue.empty():\n",
        "            # 3.5초 안에 답변이 완성되면 바로 값 리턴\n",
        "            response = response_queue.get()\n",
        "            run_flag= True\n",
        "            break\n",
        "        # 안정적인 구동을 위한 딜레이 타임 설정\n",
        "        time.sleep(0.01)\n",
        "\n",
        "    # 3.5초 내 답변이 생성되지 않을 경우\n",
        "    if run_flag== False:\n",
        "        response = timeover()\n",
        "\n",
        "    return response\n",
        "\n",
        "# 답변/사진 요청 및 응답 확인 함수\n",
        "def responseOpenAI(request,response_queue,filename):\n",
        "    # 사용자다 버튼을 클릭하여 답변 완성 여부를 다시 봤을 시\n",
        "    if '생각 다 끝났나요?' in request[\"userRequest\"][\"utterance\"]:\n",
        "        # 텍스트 파일 열기\n",
        "        with open(filename) as f:\n",
        "            last_update = f.read()\n",
        "        # 텍스트 파일 내 저장된 정보가 있을 경우\n",
        "        if len(last_update.split())>1:\n",
        "            kind = last_update.split()[0]\n",
        "            if kind == \"img\":\n",
        "                bot_res, prompt = last_update.split()[1],last_update.split()[2]\n",
        "                response_queue.put(imageResponseFormat(bot_res,prompt))\n",
        "            else:\n",
        "                bot_res = last_update[4:]\n",
        "                response_queue.put(textResponseFormat(bot_res))\n",
        "            dbReset(filename)\n",
        "\n",
        "    # 이미지 생성을 요청한 경우\n",
        "    elif '/img' in request[\"userRequest\"][\"utterance\"]:\n",
        "        dbReset(filename)\n",
        "        prompt = request[\"userRequest\"][\"utterance\"].replace(\"/img\", \"\")\n",
        "        bot_res = getImageURLFromDALLE(prompt)\n",
        "        response_queue.put(imageResponseFormat(bot_res,prompt))\n",
        "        save_log = \"img\"+ \" \" + str(bot_res) + \" \" + str(prompt)\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(save_log)\n",
        "\n",
        "    # ChatGPT 답변을 요청한 경우\n",
        "    elif '/ask' in request[\"userRequest\"][\"utterance\"]:\n",
        "        dbReset(filename)\n",
        "        prompt = request[\"userRequest\"][\"utterance\"].replace(\"/ask\", \"\")\n",
        "        bot_res = getTextFromGPT(prompt)\n",
        "        response_queue.put(textResponseFormat(bot_res))\n",
        "\n",
        "        save_log = \"ask\"+ \" \" + str(bot_res)\n",
        "        print('save_log:', save_log)\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(save_log)\n",
        "\n",
        "    #아무 답변 요청이 없는 채팅일 경우\n",
        "    else:\n",
        "        # 기본 response 값\n",
        "        base_response = {'version': '2.0', 'template': {'outputs': [], 'quickReplies': []}}\n",
        "        response_queue.put(base_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_beqDjI0xwB",
        "outputId": "8c6601c3-fa69-4fe9-bccf-8d4bf4dbec5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kakaobot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=8000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "# 구름 uvicorn kakaobot:app --reload --host=0.0.0.0 --port=80\n",
        "# !uvicorn/content/drive/MyDrive/ai_chat_openAI/kakaobot:app --reload --server.port=8000\n",
        "!uvicorn kakaobot:app --reload"
      ],
      "metadata": {
        "id": "vIjLItjgeVp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}