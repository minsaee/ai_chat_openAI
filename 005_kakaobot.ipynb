{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR/IheEZJqmBeQoMRoXjqj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsaee/ai_chat_openAI/blob/master/005_kakaobot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pZuU-sxGZpQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/MyDrive/ai_chat_openAI'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastAPIë¥¼ í™œìš©í•´ì„œ ë¡œì»¬ì„œë²„ ìƒì„±í•˜ê¸°."
      ],
      "metadata": {
        "id": "QqsvqDeDGuau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# íŒŒì´ì¬ ê¸°ë°˜ì˜ ì›¹ ì„œë²„ ìƒì„± ì˜¤í”ˆì†ŒìŠ¤\n",
        "!pip install fastapi\n",
        "\n",
        "# ë¹„ë™ê¸° ì„œë²„ ì¶”ê°€ ìƒì„± 'uvicorn'\n",
        "!pip install 'uvicorn[standard]'\n",
        "\n",
        "!pip install pyngrok\n",
        "\n",
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "id": "YXvx6oNhGi5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kakaobot.py\n",
        "from fastapi import Request, FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root ():\n",
        "  return {\"message\":\"KakaoTest\"}\n",
        "\n",
        "@app.post('/chat/')\n",
        "async def chat(request:Request):\n",
        "  kakaorequest = await request.json()\n",
        "  print(kakaorequest)\n",
        "  return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZKmUhUQHQpl",
        "outputId": "f07f2510-913a-43c3-af21-202d5d91d4f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kakaobot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=8000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# !uvicorn/content/drive/MyDrive/ai_chat_openAI/kakaobot:app --reload --server.port=8000\n",
        "!uvicorn kakaobot:app --reload"
      ],
      "metadata": {
        "id": "4NW_GNZaHe0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. FastAPI ë¡œì»¬ì„œë²„ êµ¬í˜„\n",
        "2. Ngrokìœ¼ë¡œ ë¡œì»¬ì„œë²„ ì™¸ë¶€ì—ì„œ ì ‘ì†í•  ìˆ˜ ìˆë„ë¡ êµ¬í˜„\n",
        "3. ì±—ë´‡ìƒì„±(ì±—ì§€í”¼í‹°APIë§ˆìŠ¤í„°)\n",
        "4. ì±—ë´‡êµ¬í˜„"
      ],
      "metadata": {
        "id": "kdcU5vPrSI_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ê¸°ë³¸ì„¤ì •ë‹¨ê³„\n",
        "   - í”„ë¡œê·¸ë¨ì´ ì‚¬ìš©í•˜ëŠ” íŒ¨í‚¤ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  OpenAPIì˜ APIí‚¤ë¥¼ ì§€ì •í•œë‹¤.\n",
        "2.  ê¸°ëŠ¥ í•¨ìˆ˜ êµ¬í˜„ ë‹¨ê³„\n",
        "   - í”„ë¡œê·¸ë¨ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í•¨ìˆ˜í™”í•˜ì—¬ ë©”ì¸ í•¨ìˆ˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ì •ë¦¬í•œë‹¤.\n",
        "3. ì„œë²„ ìƒì„±ë‹¨ê³„\n",
        "   - FastAPIë¥¼ í™œìš©í•˜ì—¬ ë¡œì»¬ ì„œë²„ë¥¼ ìƒì„±í•œë‹¤.\n",
        "4. ë©”ì¸ í•¨ìˆ˜ êµ¬í˜„ ë‹¨ê³„\n",
        "   - í”„ë¡œê·¸ë¨ì„ êµ¬ë™í•˜ëŠ” ë©”ì¸í•¨ìˆ˜ë¡œ ìƒí™©ì— ë§ëŠ” í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì½”ë“œë¥¼ ì§„í–‰í•œë‹¤."
      ],
      "metadata": {
        "id": "Zp-MbmnVaEbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile kakaobot.py\n",
        "### 1. ê¸°ë³¸ ì •ë³´ ì„¤ì •\n",
        "from fastapi import Request, FastAPI\n",
        "import openai\n",
        "import threading\n",
        "import time\n",
        "import queue as q\n",
        "import os\n",
        "\n",
        "API_KEY = 'sk-'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "### 2. ê¸°ëŠ¥ í•¨ìˆ˜ êµ¬í˜„\n",
        "\n",
        "## 2-1. ChatGPTì—ê²Œ ì§ˆë¬¸/ë‹µë³€ ë°›ê¸°\n",
        "def getTextFromGPT(prompt):\n",
        "  messages_prompt = [{\"role\":\"system\",\n",
        "                     \"content\":'You are a thoughtful assistant. Respond to all input in 25 words and answer in korea'}]\n",
        "  messages_prompt += [{'role':'user', 'content':prompt}]\n",
        "  response = openai.ChatCompletion.create(model = 'gpt-3.5-turbo', messages=messages_prompt)\n",
        "  message = response['choices'][0]['message']['content']\n",
        "  return message\n",
        "\n",
        "# result = getTextFromGPT('ë¹¨ê°•ì€ ì˜ì–´ë¡œ?')\n",
        "# print(result) ë¹¨ê°•ì€ ì˜ì–´ë¡œëŠ” \"red\"ì…ë‹ˆë‹¤.\n",
        "\n",
        "## 2-2. ChatGPTì˜ ë‹µë³€ì„ ì¹´ì¹´ì˜¤í†¡ ì„œë²„ë¡œ ì „ë‹¬í•˜ê¸°\n",
        "\n",
        "def textResponseFormat(bot_response):\n",
        "  response = {'version':'2.0',\n",
        "              'template':{'outputs':[{'simpleText':{'text':bot_response}}], 'quickReplies':[]}}\n",
        "  return response\n",
        "\n",
        "## 2-3 ë‹µë³€ ìš”ì²­ ë° ì‘ë‹µ í™•ì¸ í•¨ìˆ˜\n",
        "def responseOpenAI(request, response_queue, filename):\n",
        "  response_message = getTextFromGPT(request)\n",
        "  print(response_message)\n",
        "\n",
        "### 3. ì„œë²„ ìƒì„±\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root ():\n",
        "  return {\"message\":\"KakaoTest\"}\n",
        "\n",
        "@app.post('/chat/')\n",
        "async def chat(request:Request):\n",
        "  kakaorequest = await request.json()\n",
        "  print(kakaorequest)\n",
        "  return mainChat(kakaorequest)\n",
        "\n",
        "### 4. ë©”ì¸ í•¨ìˆ˜ êµ¬í˜„\n",
        "\n",
        "## 4-1. ë©”ì¸ í•¨ìˆ˜\n",
        "def mainChat(kakaorequest):\n",
        "  run_flag = False\n",
        "  start_time = time.time()\n",
        "\n",
        "  # ì‘ë‹µ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±\n",
        "  cwd = os.getcwd()\n",
        "  filename = cwd + './log/botlog.txt'\n",
        "  if not os.path.exists(filename):\n",
        "    with open(filename, 'w') as f:\n",
        "      f.write('')\n",
        "  else:\n",
        "    print('File Exists')\n",
        "\n",
        "  # ë‹µë³€ ìƒì„± í•¨ìˆ˜ ì‹¤í–‰\n",
        "  response_queue = q.Queue()\n",
        "  request_response = threading.Thread(target=responseOpenAI, args=(kakaorequest, response_queue, filename))\n",
        "  request_response.start() # ìŠ¤ë ˆë“œ ì‹¤í–‰\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc3gDe6sZnLI",
        "outputId": "8d164ce9-53f9-4b31-bb40-02ebf1c29d37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¹¨ê°•ì€ ì˜ì–´ë¡œëŠ” \"red\"ì…ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kakaobot.py\n",
        "###### ê¸°ë³¸ ì •ë³´ ì„¤ì • ë‹¨ê³„ #######\n",
        "from fastapi import Request, FastAPI\n",
        "import openai\n",
        "import threading\n",
        "import time\n",
        "import queue as q\n",
        "import os\n",
        "\n",
        "# OpenAI API KEY\n",
        "API_KEY = 'sk-'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "###### ê¸°ëŠ¥ êµ¬í˜„ ë‹¨ê³„ #######\n",
        "\n",
        "# ë©”ì„¸ì§€ ì „ì†¡\n",
        "def textResponseFormat(bot_response):\n",
        "    response = {'version': '2.0', 'template': {\n",
        "    'outputs': [{\"simpleText\": {\"text\": bot_response}}], 'quickReplies': []}}\n",
        "    return response\n",
        "\n",
        "# ì‚¬ì§„ ì „ì†¡\n",
        "def imageResponseFormat(bot_response,prompt):\n",
        "    output_text = prompt+\"ë‚´ìš©ì— ê´€í•œ ì´ë¯¸ì§€ ì…ë‹ˆë‹¤\"\n",
        "    response = {'version': '2.0', 'template': {\n",
        "    'outputs': [{\"simpleImage\": {\"imageUrl\": bot_response,\"altText\":output_text}}], 'quickReplies': []}}\n",
        "    return response\n",
        "\n",
        "# ì‘ë‹µ ì´ˆê³¼ì‹œ ë‹µë³€\n",
        "def timeover():\n",
        "    response = {\"version\":\"2.0\",\"template\":{\n",
        "      \"outputs\":[\n",
        "         {\n",
        "            \"simpleText\":{\n",
        "               \"text\":\"ì•„ì§ ì œê°€ ìƒê°ì´ ëë‚˜ì§€ ì•Šì•˜ì–´ìš”ğŸ™ğŸ™\\nì ì‹œí›„ ì•„ë˜ ë§í’ì„ ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”ğŸ‘†\"\n",
        "            }\n",
        "         }\n",
        "      ],\n",
        "      \"quickReplies\":[\n",
        "         {\n",
        "            \"action\":\"message\",\n",
        "            \"label\":\"ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?ğŸ™‹\",\n",
        "            \"messageText\":\"ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?\"\n",
        "         }]}}\n",
        "    return response\n",
        "\n",
        "# ChatGPTì—ê²Œ ì§ˆë¬¸/ë‹µë³€ ë°›ê¸°\n",
        "def getTextFromGPT(prompt):\n",
        "    messages_prompt = [{\"role\": \"system\", \"content\": 'You are a thoughtful assistant. Respond to all input in 25 words'}]\n",
        "    messages_prompt += [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages_prompt)\n",
        "    message = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return message\n",
        "\n",
        "# DALLE.2ì—ê²Œ ì§ˆë¬¸/ê·¸ë¦¼ URL ë°›ê¸°\n",
        "def getImageURLFromDALLE(prompt):\n",
        "    response = openai.Image.create(prompt=prompt,n=1,size=\"512x512\")\n",
        "    print('image response:', response)\n",
        "    image_url = response['data'][0]['url']\n",
        "    return image_url\n",
        "\n",
        "# í…ìŠ¤íŠ¸íŒŒì¼ ì´ˆê¸°í™”\n",
        "def dbReset(filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"\")\n",
        "\n",
        "###### ì„œë²„ ìƒì„± ë‹¨ê³„ #######\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"kakaoTest\"}\n",
        "\n",
        "@app.post(\"/chat/\")\n",
        "async def chat(request: Request):\n",
        "    kakaorequest = await request.json()\n",
        "    print('kakaorequest:', kakaorequest)\n",
        "    return mainChat(kakaorequest)\n",
        "\n",
        "###### ë©”ì¸ í•¨ìˆ˜ ë‹¨ê³„ #######\n",
        "\n",
        "# ë©”ì¸ í•¨ìˆ˜\n",
        "def mainChat(kakaorequest):\n",
        "\n",
        "    run_flag = False\n",
        "    start_time = time.time()\n",
        "\n",
        "    # ì‘ë‹µ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±\n",
        "    cwd = os.getcwd()\n",
        "    filename = cwd + '/log/botlog.txt'\n",
        "    if not os.path.exists(filename):\n",
        "        with open(filename, \"w\") as f:\n",
        "            f.write(\"\")\n",
        "    else:\n",
        "        print(\"File Exists\")\n",
        "\n",
        "    # ë‹µë³€ ìƒì„± í•¨ìˆ˜ ì‹¤í–‰\n",
        "    response_queue = q.Queue()\n",
        "    request_respond = threading.Thread(target=responseOpenAI,\n",
        "                                        args=(kakaorequest, response_queue,filename))\n",
        "    request_respond.start()\n",
        "\n",
        "    # ë‹µë³€ ìƒì„± ì‹œê°„ ì²´í¬\n",
        "    while (time.time() - start_time < 3.5):\n",
        "        if not response_queue.empty():\n",
        "            # 3.5ì´ˆ ì•ˆì— ë‹µë³€ì´ ì™„ì„±ë˜ë©´ ë°”ë¡œ ê°’ ë¦¬í„´\n",
        "            response = response_queue.get()\n",
        "            run_flag= True\n",
        "            break\n",
        "        # ì•ˆì •ì ì¸ êµ¬ë™ì„ ìœ„í•œ ë”œë ˆì´ íƒ€ì„ ì„¤ì •\n",
        "        time.sleep(0.01)\n",
        "\n",
        "    # 3.5ì´ˆ ë‚´ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì„ ê²½ìš°\n",
        "    if run_flag== False:\n",
        "        response = timeover()\n",
        "\n",
        "    return response\n",
        "\n",
        "# ë‹µë³€/ì‚¬ì§„ ìš”ì²­ ë° ì‘ë‹µ í™•ì¸ í•¨ìˆ˜\n",
        "def responseOpenAI(request,response_queue,filename):\n",
        "    # ì‚¬ìš©ìë‹¤ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‹µë³€ ì™„ì„± ì—¬ë¶€ë¥¼ ë‹¤ì‹œ ë´¤ì„ ì‹œ\n",
        "    if 'ìƒê° ë‹¤ ëë‚¬ë‚˜ìš”?' in request[\"userRequest\"][\"utterance\"]:\n",
        "        # í…ìŠ¤íŠ¸ íŒŒì¼ ì—´ê¸°\n",
        "        with open(filename) as f:\n",
        "            last_update = f.read()\n",
        "        # í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ ì €ì¥ëœ ì •ë³´ê°€ ìˆì„ ê²½ìš°\n",
        "        if len(last_update.split())>1:\n",
        "            kind = last_update.split()[0]\n",
        "            if kind == \"img\":\n",
        "                bot_res, prompt = last_update.split()[1],last_update.split()[2]\n",
        "                response_queue.put(imageResponseFormat(bot_res,prompt))\n",
        "            else:\n",
        "                bot_res = last_update[4:]\n",
        "                response_queue.put(textResponseFormat(bot_res))\n",
        "            dbReset(filename)\n",
        "\n",
        "    # ì´ë¯¸ì§€ ìƒì„±ì„ ìš”ì²­í•œ ê²½ìš°\n",
        "    elif '/img' in request[\"userRequest\"][\"utterance\"]:\n",
        "        dbReset(filename)\n",
        "        prompt = request[\"userRequest\"][\"utterance\"].replace(\"/img\", \"\")\n",
        "        bot_res = getImageURLFromDALLE(prompt)\n",
        "        response_queue.put(imageResponseFormat(bot_res,prompt))\n",
        "        save_log = \"img\"+ \" \" + str(bot_res) + \" \" + str(prompt)\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(save_log)\n",
        "\n",
        "    # ChatGPT ë‹µë³€ì„ ìš”ì²­í•œ ê²½ìš°\n",
        "    elif '/ask' in request[\"userRequest\"][\"utterance\"]:\n",
        "        dbReset(filename)\n",
        "        prompt = request[\"userRequest\"][\"utterance\"].replace(\"/ask\", \"\")\n",
        "        bot_res = getTextFromGPT(prompt)\n",
        "        response_queue.put(textResponseFormat(bot_res))\n",
        "\n",
        "        save_log = \"ask\"+ \" \" + str(bot_res)\n",
        "        print('save_log:', save_log)\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(save_log)\n",
        "\n",
        "    #ì•„ë¬´ ë‹µë³€ ìš”ì²­ì´ ì—†ëŠ” ì±„íŒ…ì¼ ê²½ìš°\n",
        "    else:\n",
        "        # ê¸°ë³¸ response ê°’\n",
        "        base_response = {'version': '2.0', 'template': {'outputs': [], 'quickReplies': []}}\n",
        "        response_queue.put(base_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_beqDjI0xwB",
        "outputId": "8c6601c3-fa69-4fe9-bccf-8d4bf4dbec5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kakaobot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=8000\n",
        "ngrok.set_auth_token('token')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "# êµ¬ë¦„ uvicorn kakaobot:app --reload --host=0.0.0.0 --port=80\n",
        "# !uvicorn/content/drive/MyDrive/ai_chat_openAI/kakaobot:app --reload --server.port=8000\n",
        "!uvicorn kakaobot:app --reload"
      ],
      "metadata": {
        "id": "vIjLItjgeVp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}